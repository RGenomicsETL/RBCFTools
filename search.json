[{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://rgenomicsetl.github.io/RBCFTools/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sounkou Mahamane Toure. Author, maintainer. Bonfield, James K Marshall, John Danecek, Petr Li, Heng Ohan, Valeriu Whitwham, Andrew Keane, Thomas Davies, Robert M, Pierre Lindenbaum. Copyright holder.           Authors included htslib library bcftools command line tools Zilong Li. Copyright holder.           Author vcfpp library makefiles configure strategy borrowed Duckdb C API extension API authors. Copyright holder.           Authors duckdb extension API used parquet export","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Toure S (2026). RBCFTools: 'BCFTools', 'libbcftools' 'htslib' Wrappers 'BCF'/'VCF' 'Parquet' Convertors. R package version 1.23-0.0.2.9000, https://github.com/RGenomicsETL/RBCFTools.","code":"@Manual{,   title = {RBCFTools: 'BCFTools', 'libbcftools' and 'htslib' Wrappers and 'BCF'/'VCF' to 'Parquet' Convertors},   author = {Sounkou Mahamane Toure},   year = {2026},   note = {R package version 1.23-0.0.2.9000},   url = {https://github.com/RGenomicsETL/RBCFTools}, }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"Sounkou Mahamane Toure <sounkoutoure@gmail.com> (aut, cre)  Vendored components / Copyright holders  - bcftools/htslib Authors  see files bu mostly Copyright (C) 2018 Genome Research Ltd but file dependent licences including GPL   - duckdb C API and C Extension API headers Authors    MIT Licence"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":null,"dir":"","previous_headings":"","what":"RBCFTools Agent Guidelines","title":"RBCFTools Agent Guidelines","text":"document provides guidance AI agents working RBCFTools codebase, incorporating lessons learned DuckLake extension integration, bcf_reader development, VCF data optimization patterns.","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"newsmd-format-gnu-convention","dir":"","previous_headings":"Documentation Conventions","what":"NEWS.md Format (GNU Convention)","title":"RBCFTools Agent Guidelines","text":"NEWS.md file follows GNU convention: newest entries top. version section starts # RBCFTools X.Y.Z Development versions use suffix .9000 (e.g., 1.23-0.0.2.9000) Within version, feature sections ordered newest first adding new features, add TOP current development version section Never add new entries bottom version section Example structure:","code":"# RBCFTools 1.23-0.0.2.9000 (development version)  ## Newest Feature (just added) - ...  ## Previous Feature - ...  # RBCFTools 1.23-0.0.2 (previous release) - ..."},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"core-concepts","dir":"","previous_headings":"bcf_reader DuckDB Extension","what":"Core Concepts","title":"RBCFTools Agent Guidelines","text":"bcf_reader custom DuckDB extension provides high-performance VCF/BCF file reading: - Native C implementation: Direct htslib integration fast parsing - Table function: bcf_read(path, region, tidy_format) returns DuckDB table - Projection pushdown: reads columns actually requested - Region filtering: Leverages tabix/CSI indexes fast random access","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"key-parameters","dir":"","previous_headings":"bcf_reader DuckDB Extension","what":"Key Parameters","title":"RBCFTools Agent Guidelines","text":"","code":"-- Basic usage SELECT * FROM bcf_read('variants.vcf.gz');  -- With region filter (requires index) SELECT * FROM bcf_read('variants.vcf.gz', region := 'chr1:1000-2000');  -- Tidy format: one row per variant-sample combination SELECT * FROM bcf_read('cohort.vcf.gz', tidy_format := true);  -- Combined SELECT CHROM, POS, SAMPLE_ID, FORMAT_GT  FROM bcf_read('cohort.vcf.gz', region := 'chr22', tidy_format := true);"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"tidy-format-output","dir":"","previous_headings":"bcf_reader DuckDB Extension","what":"Tidy Format Output","title":"RBCFTools Agent Guidelines","text":"tidy_format := true: - Emits N rows per variant (one per sample) instead one wide row - Adds SAMPLE_ID VARCHAR column sample name - FORMAT columns become FORMAT_GT, FORMAT_DP (sample suffix) - Ideal cohort analysis, MERGE operations, per-sample queries","code":"# R wrapper vcf_to_parquet_duckdb(\"cohort.vcf.gz\", \"output.parquet\", ext_path,   tidy_format = TRUE )"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"when-to-use-partitioning","dir":"","previous_headings":"Hive-Style Partitioning","what":"When to Use Partitioning","title":"RBCFTools Agent Guidelines","text":"Use partition_by large cohort VCFs : - need efficient per-sample queries - Data tidy format SAMPLE_ID column - Output size exceeds 100MB per partition (DuckDB best practice)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"partition-patterns","dir":"","previous_headings":"Hive-Style Partitioning","what":"Partition Patterns","title":"RBCFTools Agent Guidelines","text":"","code":"# Single column partition (most common for tidy cohort data) vcf_to_parquet_duckdb(\"cohort.vcf.gz\", \"output_dir/\", ext_path,   tidy_format = TRUE,   partition_by = \"SAMPLE_ID\" ) # Creates: output_dir/SAMPLE_ID=HG00098/data_0.parquet #          output_dir/SAMPLE_ID=HG00099/data_0.parquet  # Multi-column partition (for very large WGS cohorts) vcf_to_parquet_duckdb(\"wgs.vcf.gz\", \"output_dir/\", ext_path,   tidy_format = TRUE,   partition_by = c(\"CHROM\", \"SAMPLE_ID\") ) # Creates: output_dir/CHROM=chr1/SAMPLE_ID=HG00098/data_0.parquet"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"reading-partitioned-data","dir":"","previous_headings":"Hive-Style Partitioning","what":"Reading Partitioned Data","title":"RBCFTools Agent Guidelines","text":"","code":"-- DuckDB automatically handles Hive partitioning SELECT * FROM read_parquet('output_dir/**/*.parquet', hive_partitioning=true) WHERE SAMPLE_ID = 'HG00098';  -- Partition pruning: only reads HG00098 directory"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"bloom-filters","dir":"","previous_headings":"Hive-Style Partitioning","what":"Bloom Filters","title":"RBCFTools Agent Guidelines","text":"DuckDB auto-generates Bloom filters VARCHAR columns (like SAMPLE_ID): - Enables row group pruning even within single Parquet file - manual configuration required - Check : SELECT * parquet_metadata('file.parquet')","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"core-ducklake-concepts","dir":"","previous_headings":"DuckLake Extension API & Patterns","what":"Core DuckLake Concepts","title":"RBCFTools Agent Guidelines","text":"DuckLake DuckDB extension provides lakehouse functionality : - Metadata catalog: Stores table schemas, snapshots, metadata (can DuckDB, SQLite, PostgreSQL, MySQL) - Data storage: Parquet files local filesystem, S3, GCS, supported backends - Time travel: Snapshot-based versioning querying historical data - ACID compliance: Transaction support delete+insert pattern updates","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_1-direct-connection-recommended-for-simple-cases","dir":"","previous_headings":"DuckLake Extension API & Patterns > Connection Patterns","what":"1. Direct Connection (Recommended for simple cases)","title":"RBCFTools Agent Guidelines","text":"","code":"ATTACH 'ducklake:path/to/catalog.ducklake' AS my_lake (DATA_PATH 'path/to/parquet/');"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_2-secret-based-connection-recommended-for-production","dir":"","previous_headings":"DuckLake Extension API & Patterns > Connection Patterns","what":"2. Secret-Based Connection (Recommended for production)","title":"RBCFTools Agent Guidelines","text":"","code":"-- Create secret CREATE SECRET my_lake_secret (   TYPE ducklake,   METADATA_PATH 'path/to/catalog.ducklake',   DATA_PATH 'path/to/parquet/' );  -- Use secret ATTACH 'ducklake:my_lake_secret' AS my_lake;"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_3-multi-backend-support","dir":"","previous_headings":"DuckLake Extension API & Patterns > Connection Patterns","what":"3. Multi-Backend Support","title":"RBCFTools Agent Guidelines","text":"","code":"-- PostgreSQL backend ATTACH 'ducklake:postgres:user:pass@host:5432/db' AS lake (DATA_PATH 's3://bucket/');  -- SQLite backend   ATTACH 'ducklake:sqlite:path/to/catalog.db' AS lake (DATA_PATH 'data/');  -- MySQL backend (not recommended - has known issues) ATTACH 'ducklake:mysql:user:pass@host:3306/db' AS lake (DATA_PATH 'data/');"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"supported-attach-options","dir":"","previous_headings":"DuckLake Extension API & Patterns","what":"Supported ATTACH Options","title":"RBCFTools Agent Guidelines","text":"DuckDB v1.3+ documentation, options supported: - CREATE_IF_NOT_EXISTS (default: true) - DATA_PATH (required new lakes) - READ_ONLY (default: false) - DATA_INLINING_ROW_LIMIT (default: 0) - ENCRYPTED (default: false) - METADATA_CATALOG (default: auto-generated) - METADATA_SCHEMA (default: “main”) - METADATA_PARAMETERS (MAP parameters backend) - MIGRATE_IF_REQUIRED (default: true) - OVERRIDE_DATA_PATH (default: true) - SNAPSHOT_TIME (time travel queries) - SNAPSHOT_VERSION (time travel queries) ❌ CRITICAL: SECRET option supported ATTACH statements. Secrets must referenced connection string .","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"creating-ducklake-catalog-secrets","dir":"","previous_headings":"DuckLake Extension API & Patterns > Secret Management","what":"Creating DuckLake Catalog Secrets","title":"RBCFTools Agent Guidelines","text":"","code":"-- Named secret CREATE SECRET my_catalog (   TYPE ducklake,   METADATA_PATH 'postgres:dbname=lake',   DATA_PATH 's3://my-bucket/',   METADATA_PARAMETERS MAP {     'TYPE': 'postgres',      'SECRET': 'postgres_secret'   } );  -- Persistent secret (survives restarts) CREATE PERSISTENT SECRET my_catalog (...);"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"querying-secrets","dir":"","previous_headings":"DuckLake Extension API & Patterns > Secret Management","what":"Querying Secrets","title":"RBCFTools Agent Guidelines","text":"","code":"-- List all secrets SELECT * FROM duckdb_secrets();  -- DuckLake secrets have these columns: -- name, type, provider, persistent, storage, scope, secret_string"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"postgresql-backend","dir":"","previous_headings":"DuckLake Extension API & Patterns > Backend-Specific Requirements","what":"PostgreSQL Backend","title":"RBCFTools Agent Guidelines","text":"","code":"# Required extensions INSTALL postgres; INSTALL postgres_scanner; LOAD postgres; LOAD postgres_scanner;"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"sqlite-backend","dir":"","previous_headings":"DuckLake Extension API & Patterns > Backend-Specific Requirements","what":"SQLite Backend","title":"RBCFTools Agent Guidelines","text":"","code":"# Required extensions INSTALL sqlite_scanner; LOAD sqlite_scanner;"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"s3cloud-storage","dir":"","previous_headings":"DuckLake Extension API & Patterns > Backend-Specific Requirements","what":"S3/Cloud Storage","title":"RBCFTools Agent Guidelines","text":"","code":"# Create S3 secret first (for cloud DATA_PATH) CREATE SECRET s3_creds (   TYPE s3,   KEY_ID 'minioadmin',   SECRET 'minioadmin',    ENDPOINT 'localhost:9000',   USE_SSL false,   URL_STYLE 'path' );"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_1-error-handling-for-ducklake","dir":"","previous_headings":"Implementation Patterns for RBCFTools","what":"1. Error Handling for DuckLake","title":"RBCFTools Agent Guidelines","text":"","code":"# Always catch DuckDB extension errors tryCatch({   DBI::dbExecute(con, attach_sql) }, error = function(e) {   if (grepl(\"Unsupported option.*secret\", conditionMessage(e))) {     stop(\"SECRET option not supported in DuckLake ATTACH. Use secret_name parameter instead.\", call. = FALSE)   }   # Re-throw other DuckLake-specific errors   stop(conditionMessage(e), call. = FALSE) })"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_2-secret-string-parsing","dir":"","previous_headings":"Implementation Patterns for RBCFTools","what":"2. Secret String Parsing","title":"RBCFTools Agent Guidelines","text":"","code":"# DuckLake secrets store data as semicolon-separated string # Format: \"name=test;type=ducklake;provider=config;...;metadata_path=path;data_path=path\" parse_secret_field <- function(secret_str, field_name) {   pattern <- sprintf(\"%s=([^;]*)\", field_name)   match <- regexpr(pattern, secret_str, perl = TRUE)   if (match > 0) {     start <- attr(match, \"capture.start\")[1]     length <- attr(match, \"capture.length\")[1]     if (start > 0 && length > 0) {       return(substr(secret_str, start, start + length - 1))     }   }   return(NA_character_) }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_3-connection-string-formatting","dir":"","previous_headings":"Implementation Patterns for RBCFTools","what":"3. Connection String Formatting","title":"RBCFTools Agent Guidelines","text":"","code":"ducklake_format_connection_string <- function(backend, connection_string) {   switch(backend,     \"duckdb\" = connection_string,     \"sqlite\" = paste0(\"sqlite:\", connection_string),  # NOT sqlite://     \"postgresql\" = paste0(\"postgresql://\", connection_string),     \"mysql\" = paste0(\"mysql://\", connection_string)   ) }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"id_4-option-filtering-for-attach","dir":"","previous_headings":"Implementation Patterns for RBCFTools","what":"4. Option Filtering for ATTACH","title":"RBCFTools Agent Guidelines","text":"","code":"# Filter out unsupported options when using secrets build_attach_options <- function(opts, secret_name) {   if (!is.null(secret_name)) {     # Remove DATA_PATH when using secret (already in secret)     opts <- opts[!names(opts) %in% c(\"DATA_PATH\", \"SECRET\")]   }   # Format options for SQL   # ... (convert logicals to \"true\"/\"false\", quote strings, etc.) }"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"common-error-patterns","dir":"","previous_headings":"Debugging DuckLake Issues","what":"Common Error Patterns","title":"RBCFTools Agent Guidelines","text":"Cause: Adding SECRET option ATTACH statement Fix: Use secret name connection string instead Cause: Trying attach database different aliases Fix: Use different database files detach first Cause: Missing required scanner extensions backends Fix: Install load postgres_scanner, sqlite_scanner, etc. Cause: Using wrong protocol (sqlite:// vs sqlite:) Fix: Follow DuckLake documentation exactly","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"debugging-checklist","dir":"","previous_headings":"Debugging DuckLake Issues","what":"Debugging Checklist","title":"RBCFTools Agent Guidelines","text":"","code":"# 1. Check extension loading duckdb_extensions <- dbGetQuery(con, \"SELECT * FROM duckdb_extensions()\") if (!\"ducklake\" %in% duckdb_extensions$extensionname) {   stop(\"DuckLake extension not loaded\", call. = FALSE) }  # 2. Verify secret creation secrets <- dbGetQuery(con, \"SELECT * FROM duckdb_secrets() WHERE type='ducklake'\") if (nrow(secrets) == 0) {   warning(\"No DuckLake secrets found\", call. = FALSE) }  # 3. Test simple ATTACH first tryCatch({   dbExecute(con, \"ATTACH 'ducklake:test.ducklake' AS test\") }, error = function(e) {   cat(\"ATTACH failed:\", conditionMessage(e), \"\\n\") })"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"unit-tests-for-ducklake-functions","dir":"","previous_headings":"Testing Strategy","what":"Unit Tests for DuckLake Functions","title":"RBCFTools Agent Guidelines","text":"","code":"# Test connection string parsing expect_equal(ducklake_parse_connection_string(\"ducklake:secret_name\")$backend, \"secret\") expect_equal(ducklake_parse_connection_string(\"ducklake:path/file.ducklake\")$backend, \"duckdb\")  # Test secret creation and listing ducklake_create_catalog_secret(con, \"test\", \"duckdb\", tempfile(), tempdir()) secrets <- ducklake_list_secrets(con) expect_true(\"test\" %in% secrets$name)  # Test error handling expect_error(   ducklake_connect_catalog(con, extra_options = list(SECRET = \"bad\")),   pattern = \"SECRET option not supported\" )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"integration-tests","dir":"","previous_headings":"Testing Strategy","what":"Integration Tests","title":"RBCFTools Agent Guidelines","text":"","code":"# Test end-to-end workflow test_ducklake_workflow <- function() {   # 1. Create S3 secret for cloud storage   ducklake_create_s3_secret(con, key_id = \"test\", secret = \"test\")      # 2. Create DuckLake catalog secret   ducklake_create_catalog_secret(con, \"lake\", \"duckdb\", meta_path, data_path)      # 3. Connect using secret   ducklake_connect_catalog(con, secret_name = \"lake\", alias = \"lake\")      # 4. Load VCF data (standard format)   ducklake_load_vcf(con, \"variants\", vcf_file, ext_path)      # 5. Load VCF in tidy format with partitioning   ducklake_load_vcf(con, \"cohort_tidy\", vcf_file, ext_path,     tidy_format = TRUE,     partition_by = \"SAMPLE_ID\"   )      # 6. Verify time travel works   result <- dbGetQuery(con, \"SELECT COUNT(*) FROM lake.variants AT (VERSION => 1)\")   expect_true(nrow(result) > 0) }"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"ducklake-optimization","dir":"","previous_headings":"Performance Considerations","what":"DuckLake Optimization","title":"RBCFTools Agent Guidelines","text":"Use CREATE_IF_NOT_EXISTS=false existing catalogs reduce overhead Set appropriate DATA_INLINING_ROW_LIMIT small rows (reduces file count) Consider ENCRYPTED=true sensitive data (performance trade-) Use time travel queries carefully - version maintains full data copies","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"rbcftools-integration","dir":"","previous_headings":"Performance Considerations","what":"RBCFTools Integration","title":"RBCFTools Agent Guidelines","text":"Parquet export use optimal row group sizes (100k-1M rows) VEP/CSQ parsing preserve transcript data default Consider parallel processing large VCFs per-chromosome chunking Use tidy_format = TRUE cohort analysis workflows Use partition_by = \"SAMPLE_ID\" large cohorts (>100 samples)","code":""},{"path":[]},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"building-with-ducklake-support","dir":"","previous_headings":"Extension Development","what":"Building with DuckLake Support","title":"RBCFTools Agent Guidelines","text":"","code":"# In RBCFTools build process bcf_reader_build <- function(build_dir) {   # DuckDB extension API v1.3+   # Include DuckLake headers for integration if needed   # Maintain compatibility with both DuckDB v1.2 and v1.3 }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"version-compatibility","dir":"","previous_headings":"Extension Development","what":"Version Compatibility","title":"RBCFTools Agent Guidelines","text":"DuckDB v1.3+: Required current DuckLake features DuckDB v1.2: Limited DuckLake support, time travel Always check extension version: SELECT duckdb_version()","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"common-gotchas","dir":"","previous_headings":"","what":"Common Gotchas","title":"RBCFTools Agent Guidelines","text":"SQLite format: Use sqlite: sqlite:// connection strings Secret scope: DuckLake secrets session-unless PERSISTENT keyword used File permissions: DuckLake needs write access metadata file data directory Extension dependencies: postgres_scanner, sqlite_scanner must loaded DuckLake ATTACH Cloud credentials: S3/GCS secrets must created using cloud DATA_PATH Tidy format row explosion: tidy_format = TRUE multiplies rows sample count - plan storage accordingly Partition directory output: using partition_by, output path becomes directory, file Hive partitioning read: Always use hive_partitioning=true reading partitioned data","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"vcf_open_duckdb---open-vcf-as-duckdb-tableview","dir":"","previous_headings":"Key R Function Reference","what":"vcf_open_duckdb - Open VCF as DuckDB Table/View","title":"RBCFTools Agent Guidelines","text":"Returns vcf_duckdb object : - con: DuckDB connection - table: table/view name - is_view: boolean - row_count: row count (NULL views)","code":"# Open as lazy view (default - instant creation, re-reads VCF each query) vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path) DBI::dbGetQuery(vcf$con, \"SELECT * FROM variants WHERE CHROM = '22'\") vcf_close_duckdb(vcf)  # Parallel view (UNION ALL of per-contig reads, parallelized at query time) # Requires indexed VCF - falls back to simple view with warning if not indexed vcf <- vcf_open_duckdb(\"wgs.vcf.gz\", ext_path, threads = 8)  # Materialize to table for fast repeated queries vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path, as_view = FALSE)  # Tidy format with column selection vcf <- vcf_open_duckdb(\"cohort.vcf.gz\", ext_path,   tidy_format = TRUE,   columns = c(\"CHROM\", \"POS\", \"REF\", \"ALT\", \"SAMPLE_ID\", \"FORMAT_GT\") )  # Parallel table loading for large files (requires indexed VCF) vcf <- vcf_open_duckdb(\"wgs.vcf.gz\", ext_path, as_view = FALSE, threads = 8)  # Persistent file-backed database vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path, dbdir = \"variants.duckdb\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"vcf-export-functions","dir":"","previous_headings":"Key R Function Reference","what":"VCF Export Functions","title":"RBCFTools Agent Guidelines","text":"","code":"# Standard export vcf_to_parquet_duckdb(input_file, output_file, extension_path,   columns = NULL,           # NULL = all columns   region = NULL,            # e.g., \"chr1:1000-2000\"   compression = \"zstd\",     # \"snappy\", \"zstd\", \"gzip\", \"none\"   row_group_size = 100000L,   threads = 1L,   tidy_format = FALSE,      # TRUE = one row per variant-sample   partition_by = NULL       # e.g., \"SAMPLE_ID\" or c(\"CHROM\", \"SAMPLE_ID\") )  # Parallel export (requires indexed VCF) vcf_to_parquet_duckdb_parallel(input_file, output_file, extension_path,   threads = parallel::detectCores(),   tidy_format = FALSE,   partition_by = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"ducklake-functions","dir":"","previous_headings":"Key R Function Reference","what":"DuckLake Functions","title":"RBCFTools Agent Guidelines","text":"","code":"# Load VCF into DuckLake catalog ducklake_load_vcf(con, table, vcf_path, extension_path,   tidy_format = FALSE,   partition_by = NULL,   allow_evolution = FALSE   # TRUE = auto-add new columns )  # Time travel queries ducklake_query_snapshot(con, \"SELECT * FROM variants\", snapshot_version = 1)  # List snapshots ducklake_snapshots(con, catalog = \"lake\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/copilot-instructions.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"RBCFTools Agent Guidelines","text":"DuckLake Official Docs: https://duckdb.org/docs/extensions/ducklake DuckDB Extension API: https://duckdb.org/docs/extensions/overview.html VCF Specification: https://samtools.github.io/hts-specs/VCFv4.3.pdf DuckDB Time Travel: https://duckdb.org/docs/sql/time_travel DuckDB Partitioning: https://duckdb.org/docs/data/partitioning/hive_partitioning document updated DuckLake API evolves new patterns emerge RBCFTools development.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"rbcftools","dir":"","previous_headings":"","what":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"RBCFTools provides R bindings bcftools htslib, standard tools reading manipulating VCF/BCF files. package bundles libraries command-line tools (bcftools, bgzip, tabix), external installation required. compiled libcurl, remote file access S3, GCS, HTTP URLs supported. package also includes support streaming VCF/BCF Apache Arrow (IPC) format via nanoarrow, export Parquet format using duckdb via either duckdb nanoarrow extension bcf_reader extension bundled package.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"can install development version RBCFTools r-universe unix-alikes (support windows)","code":"install.packages(     'RBCFTools',     repos = c(               'https://rgenomicsetl.r-universe.dev',               'https://cloud.r-project.org')       )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"version-information","dir":"","previous_headings":"","what":"Version Information","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"library(RBCFTools) #> Loading required package: parallel # Get library versions bcftools_version() #> [1] \"1.23\" htslib_version() #> [1] \"1.23\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"tool-paths","dir":"","previous_headings":"","what":"Tool Paths","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"RBCFTools bundles bcftools htslib command-line tools. Use path functions locate executables","code":"bcftools_path() #> [1] \"/usr/local/lib/R/site-library/RBCFTools/bcftools/bin/bcftools\" bgzip_path() #> [1] \"/usr/local/lib/R/site-library/RBCFTools/htslib/bin/bgzip\" tabix_path() #> [1] \"/usr/local/lib/R/site-library/RBCFTools/htslib/bin/tabix\" # List all available tools bcftools_tools() #>  [1] \"bcftools\"        \"color-chrs.pl\"   \"gff2gff\"         \"gff2gff.py\"      #>  [5] \"guess-ploidy.py\" \"plot-roh.py\"     \"plot-vcfstats\"   \"roh-viz\"         #>  [9] \"run-roh.pl\"      \"vcfutils.pl\"     \"vrfs-variances\" htslib_tools() #> [1] \"annot-tsv\" \"bgzip\"     \"htsfile\"   \"ref-cache\" \"tabix\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"capabilities","dir":"","previous_headings":"","what":"Capabilities","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Check features compiled htslib","code":"# Get all capabilities as a named list htslib_capabilities() #> $configure #> [1] TRUE #>  #> $plugins #> [1] TRUE #>  #> $libcurl #> [1] TRUE #>  #> $s3 #> [1] TRUE #>  #> $gcs #> [1] TRUE #>  #> $libdeflate #> [1] TRUE #>  #> $lzma #> [1] TRUE #>  #> $bzip2 #> [1] TRUE #>  #> $htscodecs #> [1] TRUE  # Human-readable feature string htslib_feature_string() #> [1] \"build=configure libcurl=yes S3=yes GCS=yes libdeflate=yes lzma=yes bzip2=yes plugins=yes plugin-path=/usr/local/lib/R/site-library/RBCFTools/htslib/libexec/htslib: htscodecs=1.6.5\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"feature-constants","dir":"","previous_headings":"Capabilities","what":"Feature Constants","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Use HTS_FEATURE_* constants check specific features useful conditionally enabling features code.","code":"# Check individual features htslib_has_feature(HTS_FEATURE_LIBCURL)  # Remote file access via libcurl #> [1] TRUE htslib_has_feature(HTS_FEATURE_S3)        #> [1] TRUE htslib_has_feature(HTS_FEATURE_GCS)      # Google Cloud Storage #> [1] TRUE htslib_has_feature(HTS_FEATURE_LIBDEFLATE) #> [1] TRUE htslib_has_feature(HTS_FEATURE_LZMA) #> [1] TRUE htslib_has_feature(HTS_FEATURE_BZIP2) #> [1] TRUE"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"example-query-of-remote-vcf-from-s3-using-bcftools","dir":"","previous_headings":"","what":"Example Query Of Remote VCF from S3 using bcftools","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"libcurl support, bcftools can directly query remote files. count variants small region 1000 Genomes cohort VCF S3:","code":"# Setup environment for remote file access (S3/GCS) setup_hts_env()  # Build S3 URL for 1000 Genomes cohort VCF s3_base <- \"s3://1000genomes-dragen-v3.7.6/data/cohorts/\" s3_path <- \"gvcf-genotyper-dragen-3.7.6/hg19/3202-samples-cohort/\" s3_vcf_file <- \"3202_samples_cohort_gg_chr22.vcf.gz\" s3_vcf_uri <- paste0(s3_base, s3_path, s3_vcf_file) # Use processx instead of system2 res <- processx::run(   bcftools_path(),   c(\"index\", \"-n\", s3_vcf_uri),   error_on_status = FALSE,   echo = FALSE ) res$stdou #> [1] \"1910766\\n\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"vcf-to-arrow-streams-and-duckdb-bcf_reader-extension","dir":"","previous_headings":"","what":"VCF to Arrow Streams and Duckdb bcf_reader extension","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"RBCFTools provides streaming VCF/BCF Apache Arrow Stream conversion via nanoarrow. enables integration tools like duckdb Parquet format convertion serializing Arrow IPC. also support bcf_reader duckdb extension read directly duckb. nanoarrow stream conversion bcf_reader perform VCF spec conformance checks headers (similar htslib’s bcf_hdr_check_sanity()) emits R warning duckdb logs correcting non-conformant fields","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"read-vcf-as-arrow-stream","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Read VCF as Arrow Stream","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Open BCF Arrow array stream read batches","code":"bcf_file <- system.file(\"extdata\", \"1000G_3samples.bcf\", package = \"RBCFTools\") stream <- vcf_open_arrow(bcf_file, batch_size = 100L)  batch <- stream$get_next() #> Warning in x$get_schema(): FORMAT/AD should be declared as Number=R per VCF #> spec; correcting schema #> Warning in x$get_schema(): FORMAT/GQ should be Type=Integer per VCF spec, but #> header declares Type=Float; using header type #> Warning in x$get_schema(): FORMAT/GT should be declared as Number=1 per VCF #> spec; correcting schema #> Warning in x$get_schema(): FORMAT/AD should be declared as Number=R per VCF #> spec; correcting schema #> Warning in x$get_schema(): FORMAT/GQ should be Type=Integer per VCF spec, but #> header declares Type=Float; using header type #> Warning in x$get_schema(): FORMAT/GT should be declared as Number=1 per VCF #> spec; correcting schema  head(nanoarrow::convert_array(batch)) #>   CHROM   POS         ID REF ALT QUAL FILTER INFO.DP INFO.AF       INFO.CB #> 1     1 10583 rs58108140   G   A   NA   PASS    1557   0.162 UM,BI,BC,NCBI #> 2     1 11508       <NA>   A   G   NA   PASS      23    0.72         BI,BC #> 3     1 11565       <NA>   G   T   NA   PASS      45       0         BI,BC #> 4     1 13116       <NA>   T   G   NA   PASS    2400   0.016         UM,BI #> 5     1 13327       <NA>   G   C   NA   PASS    2798    0.01         BI,BC #> 6     1 14699       <NA>   C   G   NA   PASS     408    0.02         BI,BC #>   INFO.EUR_R2 INFO.AFR_R2 INFO.ASN_R2 INFO.AC INFO.AN samples.HG00098.AD #> 1       0.248          NA          NA       0       6               NULL #> 2       0.001          NA          NA       6       6               NULL #> 3          NA       0.003          NA       0       6               NULL #> 4       0.106       0.286          NA       0       6               NULL #> 5       0.396       0.481          NA       0       6               NULL #> 6       0.061       0.184          NA       0       6               NULL #>   samples.HG00098.DP samples.HG00098.GL samples.HG00098.GQ samples.HG00098.GT #> 1                 NA               NULL               3.28                0|0 #> 2                 NA               NULL               2.22                1|1 #> 3                 NA               NULL               1.48                0|0 #> 4                 NA               NULL               9.17                0|0 #> 5                 NA               NULL              15.80                0|0 #> 6                 NA               NULL               6.29                0|0 #>   samples.HG00098.GD samples.HG00098.OG samples.HG00100.AD samples.HG00100.DP #> 1                 NA                ./.               NULL                 NA #> 2                 NA                ./.               NULL                 NA #> 3                 NA                ./.               NULL                 NA #> 4                 NA                ./.               NULL                 NA #> 5                 NA                ./.               NULL                 NA #> 6                 NA                ./.               NULL                 NA #>   samples.HG00100.GL samples.HG00100.GQ samples.HG00100.GT samples.HG00100.GD #> 1               NULL               3.28                0|0                 NA #> 2               NULL               2.22                1|1                 NA #> 3               NULL               1.48                0|0                 NA #> 4               NULL               9.17                0|0                 NA #> 5               NULL              15.80                0|0                 NA #> 6               NULL               6.29                0|0                 NA #>   samples.HG00100.OG samples.HG00106.AD samples.HG00106.DP samples.HG00106.GL #> 1                ./.               NULL                 NA               NULL #> 2                ./.               NULL                 NA               NULL #> 3                ./.               NULL                 NA               NULL #> 4                ./.               NULL                 NA               NULL #> 5                ./.               2, 0                  2 0.00, -0.60, -8.78 #> 6                ./.               NULL                 NA               NULL #>   samples.HG00106.GQ samples.HG00106.GT samples.HG00106.GD samples.HG00106.OG #> 1               3.28                0|0                 NA                ./. #> 2               2.22                1|1                 NA                ./. #> 3               1.48                0|0                 NA                ./. #> 4               9.17                0|0                 NA                ./. #> 5              21.74                0|0                 NA                ./. #> 6               6.29                0|0                 NA                ./. stream$release()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"convert-to-data-frame","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Convert to Data Frame","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Convert entire BCF data.frame","code":"options(warn = -1)  # Suppress warnings df <- vcf_to_arrow(bcf_file, as = \"data.frame\") df[, c(\"CHROM\", \"POS\", \"REF\", \"ALT\", \"QUAL\")] |> head() #>   CHROM   POS REF ALT QUAL #> 1     1 10583   G   A   NA #> 2     1 11508   A   G   NA #> 3     1 11565   G   T   NA #> 4     1 13116   T   G   NA #> 5     1 13327   G   C   NA #> 6     1 14699   C   G   NA"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"write-to-arrow-ipc","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Write to Arrow IPC","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Arrow IPC (.arrows) format interoperability Arrow tools using nanoarrow’s native streaming writer","code":"# Convert BCF to Arrow IPC ipc_file <- tempfile(fileext = \".arrows\")  vcf_to_arrow_ipc(bcf_file, ipc_file)  # Read back with nanoarrow ipc_data <- as.data.frame(nanoarrow::read_nanoarrow(ipc_file)) ipc_data[, c(\"CHROM\", \"POS\", \"REF\", \"ALT\")] |> head() #>   CHROM   POS REF ALT #> 1     1 10583   G   A #> 2     1 11508   A   G #> 3     1 11565   G   T #> 4     1 13116   T   G #> 5     1 13327   G   C #> 6     1 14699   C   G"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"write-vcf-streams-to-parquet","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Write VCF Streams to Parquet","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Using duckdb convert BCF parquet file perform queries parquet file. involve vcf stream conversion data.frame Use streaming = TRUE avoid loading entire VCF R memory. streams VCF Arrow IPC (nanoarrow) Parquet via duckdb, trading memory serialization overhead using duckdb nanoarrow extension","code":"parquet_file <- tempfile(fileext = \".parquet\") vcf_to_parquet_arrow(bcf_file, parquet_file, compression = \"snappy\") #> Wrote 11 rows to /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet con <- duckdb::dbConnect(duckdb::duckdb()) pq_bcf <- DBI::dbGetQuery(con, sprintf(\"SELECT * FROM '%s' LIMIT 100\", parquet_file)) pq_me <- DBI::dbGetQuery(     con,      sprintf(\"SELECT * FROM parquet_metadata('%s')\",     parquet_file)) duckdb::dbDisconnect(con, shutdown = TRUE) pq_bcf[, c(\"CHROM\", \"POS\", \"REF\", \"ALT\")] |>   head() #>   CHROM   POS REF ALT #> 1     1 10583   G   A #> 2     1 11508   A   G #> 3     1 11565   G   T #> 4     1 13116   T   G #> 5     1 13327   G   C #> 6     1 14699   C   G pq_me |> head() #>                                   file_name row_group_id row_group_num_rows #> 1 /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet            0                 11 #> 2 /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet            0                 11 #> 3 /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet            0                 11 #> 4 /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet            0                 11 #> 5 /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet            0                 11 #> 6 /tmp/RtmpYbro6M/file2e0ca3db3d0a3.parquet            0                 11 #>   row_group_num_columns row_group_bytes column_id file_offset num_values #> 1                    36            3135         0           0         11 #> 2                    36            3135         1           0         11 #> 3                    36            3135         2           0         11 #> 4                    36            3135         3           0         11 #> 5                    36            3135         4           0         11 #> 6                    36            3135         5           0         11 #>       path_in_schema       type  stats_min  stats_max stats_null_count #> 1              CHROM BYTE_ARRAY          1          1                0 #> 2                POS     DOUBLE    10583.0    28376.0                0 #> 3                 ID BYTE_ARRAY rs58108140 rs58108140               10 #> 4                REF BYTE_ARRAY          A          T                0 #> 5 ALT, list, element BYTE_ARRAY          A          T               NA #> 6               QUAL     DOUBLE       <NA>       <NA>               11 #>   stats_distinct_count stats_min_value stats_max_value compression #> 1                    1               1               1      SNAPPY #> 2                   NA         10583.0         28376.0      SNAPPY #> 3                    1      rs58108140      rs58108140      SNAPPY #> 4                   NA               A               T      SNAPPY #> 5                   NA               A               T      SNAPPY #> 6                   NA            <NA>            <NA>      SNAPPY #>          encodings index_page_offset dictionary_page_offset data_page_offset #> 1 PLAIN_DICTIONARY                NA                      4               24 #> 2            PLAIN                NA                     NA               52 #> 3 PLAIN_DICTIONARY                NA                    146              175 #> 4            PLAIN                NA                     NA              208 #> 5            PLAIN                NA                     NA              268 #> 6            PLAIN                NA                     NA              335 #>   total_compressed_size total_uncompressed_size key_value_metadata #> 1                    48                      44               NULL #> 2                    94                     113               NULL #> 3                    62                      84               NULL #> 4                    60                      78               NULL #> 5                    67                      85               NULL #> 6                    25                      23               NULL #>   bloom_filter_offset bloom_filter_length min_is_exact max_is_exact #> 1                2261                  47         TRUE         TRUE #> 2                  NA                  NA         TRUE         TRUE #> 3                2308                  47         TRUE         TRUE #> 4                  NA                  NA         TRUE         TRUE #> 5                  NA                  NA         TRUE         TRUE #> 6                  NA                  NA           NA           NA #>   row_group_compressed_bytes geo_bbox.xmin geo_bbox.xmax geo_bbox.ymin #> 1                          1            NA            NA            NA #> 2                          1            NA            NA            NA #> 3                          1            NA            NA            NA #> 4                          1            NA            NA            NA #> 5                          1            NA            NA            NA #> 6                          1            NA            NA            NA #>   geo_bbox.ymax geo_bbox.zmin geo_bbox.zmax geo_bbox.mmin geo_bbox.mmax #> 1            NA            NA            NA            NA            NA #> 2            NA            NA            NA            NA            NA #> 3            NA            NA            NA            NA            NA #> 4            NA            NA            NA            NA            NA #> 5            NA            NA            NA            NA            NA #> 6            NA            NA            NA            NA            NA #>   geo_types #> 1      NULL #> 2      NULL #> 3      NULL #> 4      NULL #> 5      NULL #> 6      NULL bcf_larger <- system.file(\"extdata\", \"1000G.ALL.2of4intersection.20100804.genotypes.bcf\", package = \"RBCFTools\") outfile <-  tempfile(fileext = \".parquet\") vcf_to_parquet_arrow(     bcf_larger,     outfile,     streaming = TRUE,     batch_size = 10000L,     row_group_size = 100000L,     compression = \"zstd\" ) #> Wrote 11 rows to /tmp/RtmpYbro6M/file2e0ca2b667de2.parquet (streaming mode)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"query-vcf-with-duckdb-after-converting-the-stream","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Query VCF with duckdb after converting the Stream","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"SQL queries BCF using duckdb package. now somehow limited due convertion arrow streams data frame","code":"vcf_query_arrow(bcf_file, \"SELECT CHROM, COUNT(*) as n FROM vcf GROUP BY CHROM\") #>   CHROM  n #> 1     1 11  # Filter variants by position vcf_query_arrow(bcf_file, \"SELECT CHROM, POS, REF, ALT FROM vcf  LIMIT 5\") #>   CHROM   POS REF ALT #> 1     1 10583   G   A #> 2     1 11508   A   G #> 3     1 11565   G   T #> 4     1 13116   T   G #> 5     1 13327   G   C"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"query-vcf-with-duckdb-extension","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Query VCF with DuckDB Extension","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"native DuckDB extension (bcf_reader) direct SQL queries VCF/BCF files without Arrow conversion overhead. extension uses Duckb C API compatible duckb v1.2.0+","code":"# Build extension (uses package's bundled htslib) build_dir <- file.path(tempdir(), \"bcf_reader\") ext_path <- bcf_reader_build(build_dir, verbose = FALSE)  # Connect and query a VCF.gz file con <- vcf_duckdb_connect(ext_path) vcf_file <- system.file(\"extdata\", \"test_deep_variant.vcf.gz\", package = \"RBCFTools\")  # Describe schema DBI::dbGetQuery(con, sprintf(\"DESCRIBE SELECT * FROM bcf_read('%s')\", vcf_file)) #>                        column_name column_type null  key default extra #> 1                            CHROM     VARCHAR  YES <NA>    <NA>  <NA> #> 2                              POS      BIGINT  YES <NA>    <NA>  <NA> #> 3                               ID     VARCHAR  YES <NA>    <NA>  <NA> #> 4                              REF     VARCHAR  YES <NA>    <NA>  <NA> #> 5                              ALT   VARCHAR[]  YES <NA>    <NA>  <NA> #> 6                             QUAL      DOUBLE  YES <NA>    <NA>  <NA> #> 7                           FILTER   VARCHAR[]  YES <NA>    <NA>  <NA> #> 8                         INFO_END     INTEGER  YES <NA>    <NA>  <NA> #> 9      FORMAT_GT_test_deep_variant     VARCHAR  YES <NA>    <NA>  <NA> #> 10     FORMAT_GQ_test_deep_variant     INTEGER  YES <NA>    <NA>  <NA> #> 11     FORMAT_DP_test_deep_variant     INTEGER  YES <NA>    <NA>  <NA> #> 12 FORMAT_MIN_DP_test_deep_variant     INTEGER  YES <NA>    <NA>  <NA> #> 13     FORMAT_AD_test_deep_variant   INTEGER[]  YES <NA>    <NA>  <NA> #> 14    FORMAT_VAF_test_deep_variant     FLOAT[]  YES <NA>    <NA>  <NA> #> 15     FORMAT_PL_test_deep_variant   INTEGER[]  YES <NA>    <NA>  <NA> #> 16 FORMAT_MED_DP_test_deep_variant     INTEGER  YES <NA>    <NA>  <NA>  # Aggregate query DBI::dbGetQuery(con, sprintf(\"   SELECT CHROM, COUNT(*) as n_variants,           MIN(POS) as min_pos, MAX(POS) as max_pos   FROM bcf_read('%s')    GROUP BY CHROM    ORDER BY n_variants DESC    LIMIT 5\", vcf_file)) #>   CHROM n_variants min_pos   max_pos #> 1    19      35918  111129  59084689 #> 2     1      35846  536895 249211717 #> 3    17      27325    6102  81052229 #> 4    11      24472  180184 134257519 #> 5     2      22032   42993 242836470  # Export directly to Parquet parquet_out <- tempfile(fileext = \".parquet\") DBI::dbExecute(con, sprintf(\"   COPY (SELECT * FROM bcf_read('%s'))    TO '%s' (FORMAT PARQUET, COMPRESSION ZSTD)\", vcf_file, parquet_out)) #> [1] 368319  # Verify parquet file size file.info(parquet_out)$size #> [1] 3998815  # Same query on Parquet file DBI::dbGetQuery(con, sprintf(\"   SELECT CHROM, COUNT(*) as n_variants,           MIN(POS) as min_pos, MAX(POS) as max_pos   FROM '%s'    GROUP BY CHROM    ORDER BY n_variants DESC    LIMIT 5\", parquet_out)) #>   CHROM n_variants min_pos   max_pos #> 1    19      35918  111129  59084689 #> 2     1      35846  536895 249211717 #> 3    17      27325    6102  81052229 #> 4    11      24472  180184 134257519 #> 5     2      22032   42993 242836470  DBI::dbDisconnect(con)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"open-vcf-as-duckdb-tableview","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Open VCF as DuckDB Table/View","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"vcf_open_duckdb() function provides convenient interface open VCF/BCF files DuckDB tables views, similar vcf_open_arrow() Arrow streams. default creates lazy view reads VCF query - instant create memory overhead. repeated queries data, materialize table as_view = FALSE: large VCF files, use tidy format parallel loading:","code":"# Build extension ext_path <- bcf_reader_build(tempdir(), verbose = FALSE) vcf_file <- system.file(\"extdata\", \"1000G_3samples.vcf.gz\", package = \"RBCFTools\")  # Open as lazy view (default) - instant creation vcf <- vcf_open_duckdb(vcf_file, ext_path) #> Created view 'variants' from 1000G_3samples.vcf.gz print(vcf) #> VCF DuckDB Connection #> --------------------- #> Source file: 1000G_3samples.vcf.gz  #> Table name:  variants  #> Type:        VIEW (lazy)  #> Database:    in-memory  #> Tidy format: FALSE  #>  #> Use DBI::dbGetQuery(vcf$con, 'SELECT ...') to query #> Use vcf_close_duckdb(vcf) when done  # Query the view DBI::dbGetQuery(vcf$con, \"SELECT CHROM, POS, REF, ALT FROM variants LIMIT 5\") #>   CHROM   POS REF ALT #> 1     1 10583   G   A #> 2     1 11508   A   G #> 3     1 11565   G   T #> 4     1 13116   T   G #> 5     1 13327   G   C  # Close connection vcf_close_duckdb(vcf) # Materialize to in-memory table (slower to create, fast queries) vcf <- vcf_open_duckdb(vcf_file, ext_path, as_view = FALSE) #> Created table 'variants' with 11 rows from 1000G_3samples.vcf.gz print(vcf) #> VCF DuckDB Connection #> --------------------- #> Source file: 1000G_3samples.vcf.gz  #> Table name:  variants  #> Type:        TABLE (materialized)  #> Database:    in-memory  #> Tidy format: FALSE  #> Row count:   11  #>  #> Use DBI::dbGetQuery(vcf$con, 'SELECT ...') to query #> Use vcf_close_duckdb(vcf) when done  # Multiple fast queries on materialized data DBI::dbGetQuery(vcf$con, \"SELECT COUNT(*) as n FROM variants\") #>    n #> 1 11 DBI::dbGetQuery(vcf$con, \"SELECT CHROM, COUNT(*) as n FROM variants GROUP BY CHROM\") #>   CHROM  n #> 1     1 11  vcf_close_duckdb(vcf) # Tidy format with column selection vcf <- vcf_open_duckdb(   vcf_file, ext_path,   tidy_format = TRUE,   columns = c(\"CHROM\", \"POS\", \"REF\", \"ALT\", \"SAMPLE_ID\", \"FORMAT_GT\") ) #> Created view 'variants' from 1000G_3samples.vcf.gz  DBI::dbGetQuery(vcf$con, \"SELECT * FROM variants LIMIT 6\") #>   CHROM   POS REF ALT SAMPLE_ID FORMAT_GT #> 1     1 10583   G   A   HG00098       0|0 #> 2     1 10583   G   A   HG00100       0|0 #> 3     1 10583   G   A   HG00106       0|0 #> 4     1 11508   A   G   HG00098       1|1 #> 5     1 11508   A   G   HG00100       1|1 #> 6     1 11508   A   G   HG00106       1|1 vcf_close_duckdb(vcf)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"tidy-long-format-export","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Tidy (Long) Format Export","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Export VCF/BCF “tidy” format row one variant-sample combination. native tidy_format parameter bcf_reader extension transforms wide FORMAT_<field>_<sample> columns single SAMPLE_ID column plus FORMAT_<field> columns - much faster SQL-level UNNEST. format ideal combining single-sample VCFs cohort tables appending DuckLake tables MERGE operations.","code":"# Build extension ext_path <- bcf_reader_build(tempdir(), verbose = FALSE)  # Multi-sample VCF: 3 samples x 11 variants = 33 rows vcf_3samples <- system.file(\"extdata\", \"1000G_3samples.vcf.gz\", package = \"RBCFTools\") tidy_out <- tempfile(fileext = \".parquet\")  # Use tidy_format parameter directly vcf_to_parquet_duckdb(vcf_3samples, tidy_out, extension_path = ext_path, tidy_format = TRUE) #> Wrote: /tmp/RtmpYbro6M/file2e0ca7ef13265.parquet  # Query the tidy output con <- duckdb::dbConnect(duckdb::duckdb()) DBI::dbGetQuery(con, sprintf(\"   SELECT CHROM, POS, REF, SAMPLE_ID, FORMAT_GT    FROM '%s'    LIMIT 9\", tidy_out)) #>   CHROM   POS REF SAMPLE_ID FORMAT_GT #> 1     1 10583   G   HG00098       0|0 #> 2     1 10583   G   HG00100       0|0 #> 3     1 10583   G   HG00106       0|0 #> 4     1 11508   A   HG00098       1|1 #> 5     1 11508   A   HG00100       1|1 #> 6     1 11508   A   HG00106       1|1 #> 7     1 11565   G   HG00098       0|0 #> 8     1 11565   G   HG00100       0|0 #> 9     1 11565   G   HG00106       0|0  # Verify row expansion: variants * samples DBI::dbGetQuery(con, sprintf(\"   SELECT COUNT(*) as total_rows,           COUNT(DISTINCT SAMPLE_ID) as n_samples   FROM '%s'\", tidy_out)) #>   total_rows n_samples #> 1         33         3  DBI::dbDisconnect(con, shutdown = TRUE)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"vcf-header-metadata-in-parquet","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"VCF Header Metadata in Parquet","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"exporting VCF Parquet, full VCF header embedded Parquet key-value metadata default. preserves schema information (INFO, FORMAT, FILTER definitions, contigs, samples) enabling round-trip back VCF format.","code":"# Build extension ext_path <- bcf_reader_build(tempdir(), verbose = FALSE) vcf_file <- system.file(\"extdata\", \"1000G_3samples.vcf.gz\", package = \"RBCFTools\")  # Export with embedded VCF header (default) parquet_out <- tempfile(fileext = \".parquet\") vcf_to_parquet_duckdb(vcf_file, parquet_out, ext_path) #> Wrote: /tmp/RtmpYbro6M/file2e0ca5e04f9ec.parquet  # Read back the metadata meta <- parquet_kv_metadata(parquet_out) print(meta) #>                 key #> 1        vcf_header #> 2 RBCFTools_version #> 3       tidy_format #>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       value #> 1 ##fileformat=VCFv4.0\\\\x0A##FILTER=<ID=PASS,Description=\\\\x22All filters passed\\\\x22>\\\\x0A##filedat=20101112\\\\x0A##datarelease=20100804\\\\x0A##samples=629\\\\x0A##contig=<ID=1,length=249250621>\\\\x0A##description=\\\\x22Where BI calls are present, genotypes and alleles are from BI.  In there absence, UM genotypes are used.  If neither are available, no genotype information is present and the alleles are from the NCBI calls.\\\\x22\\\\x0A##FORMAT=<ID=AD,Number=A,Type=Integer,Description=\\\\x22Allelic depths for the ref and alt alleles in the order listed\\\\x22>\\\\x0A##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\\\\x22Read Depth (only filtered reads used for calling)\\\\x22>\\\\x0A##FORMAT=<ID=GL,Number=G,Type=Float,Description=\\\\x22Log-scaled likelihoods for AA,AB,BB genotypes where A=ref and B=alt; not applicable if site is not biallelic\\\\x22>\\\\x0A##FORMAT=<ID=GQ,Number=1,Type=Float,Description=\\\\x22Genotype Quality\\\\x22>\\\\x0A##FORMAT=<ID=GT,Number=A,Type=String,Description=\\\\x22Genotype\\\\x22>\\\\x0A##FORMAT=<ID=GD,Number=1,Type=Float,Description=\\\\x22Genotype dosage.  Expected count of non-ref alleles [0,2]\\\\x22>\\\\x0A##FORMAT=<ID=OG,Number=1,Type=String,Description=\\\\x22Original Genotype input to Beagle\\\\x22>\\\\x0A##INFO=<ID=AF,Number=.,Type=Float,Description=\\\\x22Allele Frequency, for each ALT allele, in the same order as listed\\\\x22>\\\\x0A##INFO=<ID=DP,Number=1,Type=Integer,Description=\\\\x22Total Depth\\\\x22>\\\\x0A##INFO=<ID=CB,Number=.,Type=String,Description=\\\\x22List of centres that called, UM (University of Michigan), BI (Broad Institute), BC (Boston College), NCBI\\\\x22>\\\\x0A##INFO=<ID=EUR_R2,Number=1,Type=Float,Description=\\\\x22R2 From Beagle based on European Samples\\\\x22>\\\\x0A##INFO=<ID=AFR_R2,Number=1,Type=Float,Description=\\\\x22R2 From Beagle based on AFRICAN Samples\\\\x22>\\\\x0A##INFO=<ID=ASN_R2,Number=1,Type=Float,Description=\\\\x22R2 From Beagle based on Asian Samples\\\\x22>\\\\x0A##bcftools_viewVersion=1.9-321-g5774f32+htslib-1.10.2-22-gbfc9f0d\\\\x0A##bcftools_viewCommand=view -O b -o 1000G.ALL.2of4intersection.20100804.genotypes.bcf 1000G.ALL.2of4intersection.20100804.genotypes.vcf; Date=Fri Apr 24 20:53:38 2020\\\\x0A##INFO=<ID=AC,Number=A,Type=Integer,Description=\\\\x22Allele count in genotypes\\\\x22>\\\\x0A##INFO=<ID=AN,Number=1,Type=Integer,Description=\\\\x22Total number of alleles in called genotypes\\\\x22>\\\\x0A##bcftools_viewVersion=1.23+htslib-1.23\\\\x0A##bcftools_viewCommand=view -s HG00098,HG00100,HG00106 -O b -o inst/extdata/1000G_3samples.bcf inst/extdata/1000G.ALL.2of4intersection.20100804.genotypes.bcf; Date=Sat Jan  3 14:41:16 2026\\\\x0A##bcftools_viewCommand=view -O z -o 1000G_3samples.vcf.gz 1000G_3samples.bcf; Date=Wed Jan  7 14:39:56 2026\\\\x0A##bcftools_viewCommand=view -h /usr/local/lib/R/site-library/RBCFTools/extdata/1000G_3samples.vcf.gz; Date=Thu Jan 15 01:18:00 2026\\\\x0A#CHROM\\\\x09POS\\\\x09ID\\\\x09REF\\\\x09ALT\\\\x09QUAL\\\\x09FILTER\\\\x09INFO\\\\x09FORMAT\\\\x09HG00098\\\\x09HG00100\\\\x09HG00106 #> 2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.23.0.0.2.9000 #> 3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     false  # Extract the VCF header (stored with escaped newlines) vcf_header <- meta[meta$key == \"vcf_header\", \"value\"] substr(vcf_header, 1, 200) #> [1] \"##fileformat=VCFv4.0\\\\x0A##FILTER=<ID=PASS,Description=\\\\x22All filters passed\\\\x22>\\\\x0A##filedat=20101112\\\\x0A##datarelease=20100804\\\\x0A##samples=629\\\\x0A##contig=<ID=1,length=249250621>\\\\x0A##description=\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"stream-remote-vcf-using-arrow-or-duckdb-extension","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Stream Remote VCF using Arrow or DuckDB Extension","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"Stream remote VCF region directly S3 using either nanoarrow based vcf_stream duckb extension","code":"s3_vcf_uri <- paste0(s3_base, s3_path, s3_vcf_file)  # Arrow stream stream <- vcf_open_arrow(     s3_vcf_uri,     region = \"chr22:16050000-16050500\",     batch_size = 1000L ) df <- as.data.frame(nanoarrow::convert_array_stream(stream)) df[, c(\"CHROM\", \"POS\", \"REF\", \"ALT\")] |> head() #>   CHROM      POS REF                  ALT #> 1 chr22 16050036   A C        , <NON_REF> #> 2 chr22 16050151   T G        , <NON_REF> #> 3 chr22 16050213   C T        , <NON_REF> #> 4 chr22 16050219   C A        , <NON_REF> #> 5 chr22 16050224   A C        , <NON_REF> #> 6 chr22 16050229   C A        , <NON_REF>   # Query remote VCF with bcf_reader extension  vcf_query_duckdb(     s3_vcf_uri,     ext_path,     region = \"chr22:16050000-16050500\",     query = \"SELECT CHROM, POS, REF, ALT FROM vcf LIMIT 5\" ) #>   CHROM      POS REF          ALT #> 1 chr22 16050036   A C, <NON_REF> #> 2 chr22 16050151   T G, <NON_REF> #> 3 chr22 16050213   C T, <NON_REF> #> 4 chr22 16050219   C A, <NON_REF> #> 5 chr22 16050224   A C, <NON_REF>"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"custom-index-file-path","dir":"","previous_headings":"VCF to Arrow Streams and Duckdb bcf_reader extension","what":"Custom Index File Path","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"region queries, index file required. default, RBCFTools looks .tbi (tabix) .csi indexes using standard naming conventions. non-standard index locations presigned URLs custom paths, use index parameter. Index files required region queries; reading entire file without region filter, index needed. VCF files try .tbi first fall back .csi, BCF files use .csi .","code":"# Explicit index file path bcf_file <- system.file(\"extdata\", \"1000G_3samples.bcf\", package = \"RBCFTools\") csi_index <- system.file(\"extdata\", \"1000G_3samples.bcf.csi\", package = \"RBCFTools\")  stream <- vcf_open_arrow(bcf_file, index = csi_index) batch <- stream$get_next() nanoarrow::convert_array(batch)[, c(\"CHROM\", \"POS\", \"REF\")] |> head(3) #>   CHROM   POS REF #> 1     1 10583   G #> 2     1 11508   A #> 3     1 11565   G # Alternative: htslib ##idx## syntax in filename filename_with_idx <- paste0(bcf_file, \"##idx##\", csi_index) stream2 <- vcf_open_arrow(filename_with_idx) batch2 <- stream2$get_next() nanoarrow::convert_array(batch2)[, c(\"CHROM\", \"POS\", \"REF\")] |> head(3) #>   CHROM   POS REF #> 1     1 10583   G #> 2     1 11508   A #> 3     1 11565   G"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"example-application-ducklake-etl","dir":"","previous_headings":"","what":"Example Application: DuckLake ETL","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"DuckLake integrated data lake catalog format. two components, parquet files storage metadata dababase layer.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"ducklake-etl-to-minio-storage-backend","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"DuckLake ETL to MinIO Storage backend","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"mimick S3 backend DuckLake storage use minio, convert VCF files parquet insert DuckLake query lake. lake local duckdb metadata database example","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"setup-up-minio-storage-backend","dir":"","previous_headings":"Example Application: DuckLake ETL > DuckLake ETL to MinIO Storage backend","what":"Setup up minio storage backend","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"start seting configuring minio server","code":"# DuckLake with S3-compatible storage using local MinIO if (!requireNamespace(\"processx\", quietly = TRUE)) stop(\"processx required\") bin_dir <- file.path(tempdir(), \"ducklake_bins\") dir.create(bin_dir, recursive = TRUE, showWarnings = FALSE)  # Use installed MinIO and MC binaries minio_bin <- Sys.which('minio') mc_bin <- Sys.which('mc')  # Start MinIO (ephemeral) and configure mc data_dir <- file.path(tempdir(), \"ducklake_minio\") dir.create(data_dir, recursive = TRUE, showWarnings = FALSE) port <- 9000 endpoint <- sprintf(\"127.0.0.1:%d\", port)  # Start MinIO server in background cmd <- sprintf(   \"%s server %s --address %s > /dev/null 2>&1 & echo $!\",   shQuote(minio_bin),   shQuote(data_dir),   endpoint ) pid_output <- processx::run(\"sh\", c(\"-c\", cmd), echo = FALSE)$stdout pid <- as.integer(pid_output) pid #> [1] 190687 # Give MinIO time to start Sys.sleep(10)  # Configure mc alias # remove previous alias processx::run(   mc_bin,   c(\"alias\", \"remove\", \"ducklake_local\"),   error_on_status = FALSE,   echo = FALSE ) #> $status #> [1] 1 #>  #> $stdout #> [1] \"\" #>  #> $stderr #> [1] \"mc: <ERROR> No such alias `ducklake_local` found. Use `mc alias set mycloud ducklake_local ...` to add an alias. Use the alias for S3 operations.\\n\" #>  #> $timeout #> [1] FALSE mc_cmd_args <- c(\"alias\", \"set\", \"ducklake_local\",                    paste0(\"http://\", endpoint), \"minioadmin\", \"minioadmin\") processx::run(mc_bin, mc_cmd_args, echo = FALSE) #> $status #> [1] 0 #>  #> $stdout #> [1] \"Added `ducklake_local` successfully.\\n\" #>  #> $stderr #> [1] \"\" #>  #> $timeout #> [1] FALSE  # Create bucket with unique name bucket <- sprintf(\"readme-demo-%d\", as.integer(Sys.time())) bucket_cmd_args <- c(\"mb\", paste0(\"ducklake_local/\", bucket)) processx::run(mc_bin, bucket_cmd_args, echo = FALSE) #> $status #> [1] 0 #>  #> $stdout #> [1] \"Bucket created successfully `ducklake_local/readme-demo-1768436297`.\\n\" #>  #> $stderr #> [1] \"\" #>  #> $timeout #> [1] FALSE  # Store variables for later use minio_endpoint <- endpoint bucket_name <- bucket data_root_s3 <- paste0(\"s3://\", bucket_name) data_path_s3 <- paste0(data_root_s3, \"/data/\") mc_path <- mc_bin"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"attach-a-ducklake","dir":"","previous_headings":"Example Application: DuckLake ETL > DuckLake ETL to MinIO Storage backend","what":"Attach a DuckLake","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"con <- duckdb::dbConnect(duckdb::duckdb(config = list(   allow_unsigned_extensions = \"true\",   enable_external_access = \"true\" ))) stopifnot(DBI::dbIsValid(con))  DBI::dbExecute(con, \"INSTALL httpfs\") #> [1] 0 DBI::dbExecute(con, \"LOAD httpfs\") #> [1] 0 DBI::dbExecute(con, \"INSTALL ducklake FROM core_nightly\") #> [1] 0 DBI::dbExecute(con, \"LOAD ducklake\") #> [1] 0  # Provide S3 credentials/endpoints for MinIO Sys.setenv(   AWS_ACCESS_KEY_ID = \"minioadmin\",   AWS_SECRET_ACCESS_KEY = \"minioadmin\",   AWS_DEFAULT_REGION = \"us-east-1\",   AWS_S3_ENDPOINT = paste0(\"http://\", minio_endpoint),   AWS_S3_USE_HTTPS = \"FALSE\",   AWS_S3_FORCE_PATH_STYLE = \"TRUE\",   AWS_EC2_METADATA_DISABLED = \"TRUE\" )  ducklake_create_s3_secret(   con,   name = \"ducklake_minio\",   key_id = \"minioadmin\",   secret = \"minioadmin\",   endpoint = minio_endpoint,   region = \"us-east-1\",   use_ssl = FALSE )  metadata_path <- file.path(tempdir(), sprintf(\"ducklake_meta_%s.ducklake\", bucket_name)) ducklake_attach(   con,   metadata_path = metadata_path,   data_path = data_path_s3,   alias = \"lake\",   extra_options = list(OVERRIDE_DATA_PATH = TRUE) )  # Work inside the attached lake database DBI::dbExecute(con, \"USE lake\") #> [1] 0"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"write-a-vcf-into-minio-and-register-to-the-lake","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"Write a VCF into minio and register to the Lake","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"# Ensure we are operating inside the DuckLake catalog DBI::dbExecute(con, \"USE lake\") #> [1] 0  # Load variants via fast VCF to Parquet conversion vcf_file <- system.file(\"extdata\", \"test_deep_variant.vcf.gz\", package = \"RBCFTools\") ext_path <- bcf_reader_build(tempdir()) #> bcf_reader extension already exists at: /tmp/RtmpYbro6M/build/bcf_reader.duckdb_extension #> Use force=TRUE to rebuild. ducklake_load_vcf(   con,   table = \"variants\",   vcf_path = vcf_file,   extension_path = ext_path,   threads = 1,   tidy_format = TRUE ) #> Wrote: /tmp/RtmpYbro6M/variants_20260115_011817.parquet #> Note: method with signature 'DBIConnection#Id' chosen for function 'dbExistsTable', #>  target signature 'duckdb_connection#Id'. #>  \"duckdb_connection#ANY\" would also be valid"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"add-another-vcf-file-with-different-schema","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"Add another VCF file with different schema","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"DuckLake supports schema evolution via ALTER TABLE. Use allow_evolution = TRUE automatically add new columns incoming files.","code":"DBI::dbExecute(con, \"USE lake\") #> [1] 0 variants_count <- DBI::dbGetQuery(con, \"SELECT COUNT(*) as n FROM variants\")$n[1] variants_count #> [1] 368319  vcf_file2 <- system.file(\"extdata\", \"test_vep.vcf\", package = \"RBCFTools\") local_parquet2 <- tempfile(fileext = \".parquet\") vcf_to_parquet_duckdb(vcf_file2, local_parquet2, extension_path = ext_path, tidy_format = TRUE) #> Wrote: /tmp/RtmpYbro6M/file2e0ca298e3c82.parquet  DBI::dbGetQuery(con, sprintf(\"SELECT COUNT(*) as n FROM read_parquet('%s')\", local_parquet2)) #>     n #> 1 802  s3_parquet2 <- paste0(data_path_s3, \"variants/variants_vep.parquet\") mc_cmd_args <- c(\"cp\", local_parquet2, paste0(\"ducklake_local/\", bucket_name, \"/data/variants/variants_vep.parquet\")) processx::run(mc_bin, mc_cmd_args, echo = FALSE) #> $status #> [1] 0 #>  #> $stdout #> [1] \"`/tmp/RtmpYbro6M/file2e0ca298e3c82.parquet` -> `ducklake_local/readme-demo-1768436297/data/variants/variants_vep.parquet`\\n┌────────────┬─────────────┬──────────┬────────────┐\\n│ Total      │ Transferred │ Duration │ Speed      │\\n│ 122.34 KiB │ 122.34 KiB  │ 00m00s   │ 7.93 MiB/s │\\n└────────────┴─────────────┴──────────┴────────────┘\\n\" #>  #> $stderr #> [1] \"\" #>  #> $timeout #> [1] FALSE  DBI::dbGetQuery(con, sprintf(\"SELECT COUNT(*) as n FROM read_parquet('%s')\", s3_parquet2)) #>     n #> 1 802  ducklake_register_parquet(   con,   table = \"lake.variants\",   parquet_files = s3_parquet2,   create_table = FALSE,   allow_evolution = TRUE )  variants_count_after <- DBI::dbGetQuery(con, \"SELECT COUNT(*) as n FROM variants\")$n[1] variants_count_after #> [1] 369121"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"list-lake-content","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"List lake content","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"DBI::dbExecute(con, \"USE lake\") #> [1] 0  DBI::dbGetQuery(con, \"   SELECT      COUNT(*) as total_variants,     COUNT(DISTINCT CHROM) as n_chromosomes,     MIN(POS) as min_position,     MAX(POS) as max_position   FROM variants \") #>   total_variants n_chromosomes min_position max_position #> 1         369121            25          152    249211717  DBI::dbGetQuery(con, \"DESCRIBE variants\") |>   head(20) #>        column_name column_type null  key default extra #> 1            CHROM     VARCHAR  YES <NA>    <NA>  <NA> #> 2              POS      BIGINT  YES <NA>    <NA>  <NA> #> 3               ID     VARCHAR  YES <NA>    <NA>  <NA> #> 4              REF     VARCHAR  YES <NA>    <NA>  <NA> #> 5              ALT   VARCHAR[]  YES <NA>    <NA>  <NA> #> 6             QUAL      DOUBLE  YES <NA>    <NA>  <NA> #> 7           FILTER   VARCHAR[]  YES <NA>    <NA>  <NA> #> 8         INFO_END     INTEGER  YES <NA>    <NA>  <NA> #> 9        SAMPLE_ID     VARCHAR  YES <NA>    <NA>  <NA> #> 10       FORMAT_GT     VARCHAR  YES <NA>    <NA>  <NA> #> 11       FORMAT_GQ     INTEGER  YES <NA>    <NA>  <NA> #> 12       FORMAT_DP     INTEGER  YES <NA>    <NA>  <NA> #> 13   FORMAT_MIN_DP     INTEGER  YES <NA>    <NA>  <NA> #> 14       FORMAT_AD   INTEGER[]  YES <NA>    <NA>  <NA> #> 15      FORMAT_VAF     FLOAT[]  YES <NA>    <NA>  <NA> #> 16       FORMAT_PL   INTEGER[]  YES <NA>    <NA>  <NA> #> 17   FORMAT_MED_DP     INTEGER  YES <NA>    <NA>  <NA> #> 18      VEP_Allele   VARCHAR[]  YES <NA>    <NA>  <NA> #> 19 VEP_Consequence   VARCHAR[]  YES <NA>    <NA>  <NA> #> 20      VEP_IMPACT   VARCHAR[]  YES <NA>    <NA>  <NA> ducklake_list_files(con, \"lake\", \"variants\") #>                                                                                              data_file #> 1 s3://readme-demo-1768436297/data/main/variants/ducklake-019bbf04-7352-74aa-b6b3-e506f83ae19c.parquet #> 2                                       s3://readme-demo-1768436297/data/variants/variants_vep.parquet #>   data_file_size_bytes data_file_footer_size data_file_encryption_key #> 1              5751964                  6113                     NULL #> 2               125274                 16367                     NULL #>   delete_file delete_file_size_bytes delete_file_footer_size #> 1        <NA>                     NA                      NA #> 2        <NA>                     NA                      NA #>   delete_file_encryption_key #> 1                       NULL #> 2                       NULL"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"snapshots-and-time-travel","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"Snapshots and time travel","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"ducklake_snapshots(con, \"lake\") |> head() #>   snapshot_id       snapshot_time schema_version #> 1           0 2026-01-15 00:18:17              0 #> 2           1 2026-01-15 00:18:18              1 #> 3           2 2026-01-15 00:18:18              2 #> 4           3 2026-01-15 00:18:18              3 #> 5           4 2026-01-15 00:18:18              4 #> 6           5 2026-01-15 00:18:18              5 #>                                                  changes author commit_message #> 1                                  schemas_created, main   <NA>           <NA> #> 2 tables_created, tables_inserted_into, main.variants, 1   <NA>           <NA> #> 3                                      tables_altered, 1   <NA>           <NA> #> 4                                      tables_altered, 1   <NA>           <NA> #> 5                                      tables_altered, 1   <NA>           <NA> #> 6                                      tables_altered, 1   <NA>           <NA> #>   commit_extra_info #> 1              <NA> #> 2              <NA> #> 3              <NA> #> 4              <NA> #> 5              <NA> #> 6              <NA> ducklake_snapshots(con, \"lake\") |> tail() #>    snapshot_id       snapshot_time schema_version                 changes #> 84          83 2026-01-15 00:18:19             83       tables_altered, 1 #> 85          84 2026-01-15 00:18:19             84       tables_altered, 1 #> 86          85 2026-01-15 00:18:19             85       tables_altered, 1 #> 87          86 2026-01-15 00:18:19             86       tables_altered, 1 #> 88          87 2026-01-15 00:18:19             87       tables_altered, 1 #> 89          88 2026-01-15 00:18:19             87 tables_inserted_into, 1 #>    author commit_message commit_extra_info #> 84   <NA>           <NA>              <NA> #> 85   <NA>           <NA>              <NA> #> 86   <NA>           <NA>              <NA> #> 87   <NA>           <NA>              <NA> #> 88   <NA>           <NA>              <NA> #> 89   <NA>           <NA>              <NA>  ducklake_current_snapshot(con, \"lake\") #> [1] 88"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"configuration","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"Configuration","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"ducklake_options(con, \"lake\") #>   option_name                                                      description #> 1  created_by                                  Tool used to write the DuckLake #> 2   data_path                                               Path to data files #> 3   encrypted Whether or not to encrypt Parquet files written to the data path #> 4     version                                          DuckLake format version #>                               value  scope scope_entry #> 1                 DuckDB d1dc88f950 GLOBAL        <NA> #> 2 s3://readme-demo-1768436297/data/ GLOBAL        <NA> #> 3                             false GLOBAL        <NA> #> 4                               0.3 GLOBAL        <NA> ducklake_set_option(con, \"lake\", \"parquet_compression\", \"zstd\") ducklake_options(con, \"lake\") #>           option_name #> 1          created_by #> 2           data_path #> 3           encrypted #> 4 parquet_compression #> 5             version #>                                                                                        description #> 1                                                                  Tool used to write the DuckLake #> 2                                                                               Path to data files #> 3                                 Whether or not to encrypt Parquet files written to the data path #> 4 Compression algorithm for Parquet files (uncompressed, snappy, gzip, zstd, brotli, lz4, lz4_raw) #> 5                                                                          DuckLake format version #>                               value  scope scope_entry #> 1                 DuckDB d1dc88f950 GLOBAL        <NA> #> 2 s3://readme-demo-1768436297/data/ GLOBAL        <NA> #> 3                             false GLOBAL        <NA> #> 4                              zstd GLOBAL        <NA> #> 5                               0.3 GLOBAL        <NA> DBI::dbDisconnect(con, shutdown = TRUE) tools::pskill(pid)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"supported-metadata-databases","dir":"","previous_headings":"Example Application: DuckLake ETL","what":"Supported Metadata Databases","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"DuckLake supports multiple catalog backends DuckDB : ducklake:path//catalog.ducklake SQLite: ducklake:sqlite://path//catalog.db PostgreSQL : ducklake:postgresql://user:pass@host:5432/db MySQL: ducklake:mysql://user:pass@host:3306/db","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"connection-methods","dir":"","previous_headings":"Example Application: DuckLake ETL > Supported Metadata Databases","what":"Connection Methods","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"package provides helpers different metadata databases","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"direct-connection","dir":"","previous_headings":"Example Application: DuckLake ETL > Supported Metadata Databases","what":"Direct Connection","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"# DuckDB backend ducklake_connect_catalog(   con,   backend = \"duckdb\",   connection_string = \"catalog.ducklake\",   data_path = \"s3://bucket/data/\",   alias = \"lake\" )  # PostgreSQL backend ducklake_connect_catalog(   con,   backend = \"postgresql\",    connection_string = \"user:pass@host:5432/db\",   data_path = \"s3://bucket/data/\",   alias = \"lake\" )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"secret-based-connection","dir":"","previous_headings":"Example Application: DuckLake ETL > Supported Metadata Databases > Direct Connection","what":"Secret-based Connection:**","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"","code":"# Create catalog secret ducklake_create_catalog_secret(   con,   name = \"pg_catalog\",   backend = \"postgresql\",   connection_string = \"user:pass@host:5432/db\",   data_path = \"s3://bucket/data/\" )  # Connect using secret ducklake_connect_catalog(   con,   secret_name = \"pg_catalog\",   alias = \"lake\" )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"command-line-utilities","dir":"","previous_headings":"","what":"Command-Line utilities","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"CLI tools provided VCF Parquet conversion querying, including threaded chunking based contigs using either bcf_reader extension via Arrow IPC","code":"# Get paths using system.file SCRIPT=$(Rscript -e \"cat(system.file('scripts', 'vcf2parquet_duckdb.R', package='RBCFTools'))\") BCF=$(Rscript -e \"cat(system.file('extdata', 'test_deep_variant.vcf.gz', package='RBCFTools'))\") OUT_PQ=$(mktemp --suffix=.parquet) Log=$(mktemp --suffix=.log)  # Convert BCF to Parquet time $SCRIPT convert --quiet --tidy -i $BCF -o $OUT_PQ -t 4  > $Log 2>&1  cat $Log  # Query with DuckDB SQL $SCRIPT query -i $OUT_PQ -q \"SELECT * FROM parquet_scan('$OUT_PQ') LIMIT 5\"  # Describe table structure $SCRIPT query -i $OUT_PQ -q \"DESCRIBE SELECT * FROM parquet_scan('$OUT_PQ')\"  # Show schema $SCRIPT schema  --quiet -i $BCF   # File info $SCRIPT info -i $OUT_PQ   rm -f $OUT_PQ #>  #> real 0m1.683s #> user 0m3.810s #> sys  0m2.054s #> Building bcf_reader extension... #>   Build directory: /tmp/Rtmp5Hr8iH  #> Building bcf_reader extension... #>   Build directory: /tmp/Rtmp5Hr8iH #>   Using htslib from: /usr/local/lib/R/site-library/RBCFTools/htslib/lib #>   Running: make with explicit htslib paths #> make[1]: Entering directory '/tmp/Rtmp5Hr8iH' #> rm -rf build #> make[1]: Leaving directory '/tmp/Rtmp5Hr8iH' #> make[1]: Entering directory '/tmp/Rtmp5Hr8iH' #> mkdir -p build #> gcc -O2 -Wall -Wextra -Wno-unused-parameter -fPIC -I/usr/local/lib/R/site-library/RBCFTools/htslib/include -I. -c bcf_reader.c -o build/bcf_reader.o #> gcc -O2 -Wall -Wextra -Wno-unused-parameter -fPIC -I/usr/local/lib/R/site-library/RBCFTools/htslib/include -I. -c vep_parser.c -o build/vep_parser.o #> gcc -shared -fPIC -o build/libbcf_reader.so build/bcf_reader.o build/vep_parser.o -L/usr/local/lib/R/site-library/RBCFTools/htslib/lib -Wl,-rpath,/usr/local/lib/R/site-library/RBCFTools/htslib/lib -lhts #> Creating DuckDB extension with metadata... #> Created: build/bcf_reader.duckdb_extension #>   Platform: linux_amd64 #>   DuckDB Version: v1.2.0 #>   Extension Version: 1.0.0 #> make[1]: Leaving directory '/tmp/Rtmp5Hr8iH' #> Extension built: /tmp/Rtmp5Hr8iH/build/bcf_reader.duckdb_extension #> ✓ Extension ready: /tmp/Rtmp5Hr8iH/build/bcf_reader.duckdb_extension  #>  #> Converting VCF to Parquet (DuckDB mode)... #>   Input: /usr/local/lib/R/site-library/RBCFTools/extdata/test_deep_variant.vcf.gz  #>   Output: /tmp/tmp.9PWy8RMQws.parquet  #>   Compression: zstd  #>   Row group size: 100000  #>   Threads: 4  #>   Format: tidy (one row per variant-sample) #> Processing 25 contigs (out of 86 in header) using 4 threads (DuckDB mode) #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0004.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0003.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0002.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0001.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0008.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0007.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0006.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0005.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0012.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0010.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0011.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0009.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0014.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0015.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0013.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0016.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0018.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0020.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0017.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0019.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0022.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0024.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0021.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0023.parquet #> Wrote: /tmp/Rtmp5Hr8iH/vcf_duckdb_parallel_2e9cf4cac0716/contig_0025.parquet #> Merging temporary Parquet files... to /tmp/tmp.9PWy8RMQws.parquet #> Merged 25 parquet files -> tmp.9PWy8RMQws.parquet (368319 rows) #>  #> ✓ Conversion complete! #>   Time: 1.00 seconds #>   Output size: 3.77 MB #> Running query on Parquet file... #>   CHROM    POS   ID REF ALT QUAL  FILTER INFO_END         SAMPLE_ID FORMAT_GT #> 1     1 536895 <NA>   T   C  0.1 RefCall       NA test_deep_variant       ./. #> 2     1 536924 <NA>   G   A  0.1 RefCall       NA test_deep_variant       ./. #> 3     1 536948 <NA>   A   G  0.0 RefCall       NA test_deep_variant       0/0 #> 4     1 536986 <NA>   G   T  0.0 RefCall       NA test_deep_variant       0/0 #> 5     1 544490 <NA>   A   G  0.8 RefCall       NA test_deep_variant       ./. #>   FORMAT_GQ FORMAT_DP FORMAT_MIN_DP FORMAT_AD FORMAT_VAF FORMAT_PL #> 1        18       106            NA    46, 52   0.490566 0, 19, 25 #> 2        18       118            NA    55, 60   0.508475 0, 21, 20 #> 3        31       104            NA    91, 13      0.125 0, 31, 38 #> 4        23       115            NA    55, 60   0.521739 0, 23, 29 #> 5         8        10            NA      6, 4        0.4  0, 7, 15 #>   FORMAT_MED_DP #> 1            NA #> 2            NA #> 3            NA #> 4            NA #> 5            NA #> Running query on Parquet file... #>      column_name column_type null  key default extra #> 1          CHROM     VARCHAR  YES <NA>    <NA>  <NA> #> 2            POS      BIGINT  YES <NA>    <NA>  <NA> #> 3             ID     VARCHAR  YES <NA>    <NA>  <NA> #> 4            REF     VARCHAR  YES <NA>    <NA>  <NA> #> 5            ALT   VARCHAR[]  YES <NA>    <NA>  <NA> #> 6           QUAL      DOUBLE  YES <NA>    <NA>  <NA> #> 7         FILTER   VARCHAR[]  YES <NA>    <NA>  <NA> #> 8       INFO_END     INTEGER  YES <NA>    <NA>  <NA> #> 9      SAMPLE_ID     VARCHAR  YES <NA>    <NA>  <NA> #> 10     FORMAT_GT     VARCHAR  YES <NA>    <NA>  <NA> #> 11     FORMAT_GQ     INTEGER  YES <NA>    <NA>  <NA> #> 12     FORMAT_DP     INTEGER  YES <NA>    <NA>  <NA> #> 13 FORMAT_MIN_DP     INTEGER  YES <NA>    <NA>  <NA> #> 14     FORMAT_AD   INTEGER[]  YES <NA>    <NA>  <NA> #> 15    FORMAT_VAF     FLOAT[]  YES <NA>    <NA>  <NA> #> 16     FORMAT_PL   INTEGER[]  YES <NA>    <NA>  <NA> #> 17 FORMAT_MED_DP     INTEGER  YES <NA>    <NA>  <NA> #> Building bcf_reader extension... #>   Build directory: /tmp/Rtmp282896  #> Building bcf_reader extension... #>   Build directory: /tmp/Rtmp282896 #>   Using htslib from: /usr/local/lib/R/site-library/RBCFTools/htslib/lib #>   Running: make with explicit htslib paths #> make[1]: Entering directory '/tmp/Rtmp282896' #> rm -rf build #> make[1]: Leaving directory '/tmp/Rtmp282896' #> make[1]: Entering directory '/tmp/Rtmp282896' #> mkdir -p build #> gcc -O2 -Wall -Wextra -Wno-unused-parameter -fPIC -I/usr/local/lib/R/site-library/RBCFTools/htslib/include -I. -c bcf_reader.c -o build/bcf_reader.o #> gcc -O2 -Wall -Wextra -Wno-unused-parameter -fPIC -I/usr/local/lib/R/site-library/RBCFTools/htslib/include -I. -c vep_parser.c -o build/vep_parser.o #> gcc -shared -fPIC -o build/libbcf_reader.so build/bcf_reader.o build/vep_parser.o -L/usr/local/lib/R/site-library/RBCFTools/htslib/lib -Wl,-rpath,/usr/local/lib/R/site-library/RBCFTools/htslib/lib -lhts #> Creating DuckDB extension with metadata... #> Created: build/bcf_reader.duckdb_extension #>   Platform: linux_amd64 #>   DuckDB Version: v1.2.0 #>   Extension Version: 1.0.0 #> make[1]: Leaving directory '/tmp/Rtmp282896' #> Extension built: /tmp/Rtmp282896/build/bcf_reader.duckdb_extension #> ✓ Extension ready: /tmp/Rtmp282896/build/bcf_reader.duckdb_extension  #>  #> VCF DuckDB Schema for: /usr/local/lib/R/site-library/RBCFTools/extdata/test_deep_variant.vcf.gz  #>  #>                      column_name column_type #>                            CHROM   character #>                              POS     numeric #>                               ID   character #>                              REF   character #>                              ALT        list #>                             QUAL     numeric #>                           FILTER        list #>                         INFO_END     integer #>      FORMAT_GT_test_deep_variant   character #>      FORMAT_GQ_test_deep_variant     integer #>      FORMAT_DP_test_deep_variant     integer #>  FORMAT_MIN_DP_test_deep_variant     integer #>      FORMAT_AD_test_deep_variant        list #>     FORMAT_VAF_test_deep_variant        list #>      FORMAT_PL_test_deep_variant        list #>  FORMAT_MED_DP_test_deep_variant     integer #> Parquet File Information: /tmp/tmp.9PWy8RMQws.parquet  #>  #> File size: 3.77 MB  #> Total rows: 368319  #> Number of columns: 28  #>  #> Schema (top-level columns): #>           name       type #>          CHROM BYTE_ARRAY #>            POS      INT64 #>             ID BYTE_ARRAY #>            REF BYTE_ARRAY #>            ALT       <NA> #>           QUAL     DOUBLE #>         FILTER       <NA> #>       INFO_END      INT32 #>      SAMPLE_ID BYTE_ARRAY #>      FORMAT_GT BYTE_ARRAY #>      FORMAT_GQ      INT32 #>      FORMAT_DP      INT32 #>  FORMAT_MIN_DP      INT32 #>      FORMAT_AD       <NA> #>     FORMAT_VAF       <NA> #>      FORMAT_PL       <NA> #>  FORMAT_MED_DP      INT32"},{"path":"https://rgenomicsetl.github.io/RBCFTools/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"BCFTools, libbcftools and htslib Wrappers and BCF/VCF to Parquet Convertors","text":"bcftools documentation bcftools GitHub htslib GitHub arrow-nanoarrow Ducklake minio Example","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/RBCFTools-package.html","id":null,"dir":"Reference","previous_headings":"","what":"RBCFTools: 'BCFTools', 'libbcftools' and 'htslib' Wrappers and 'BCF'/'VCF' to 'Parquet' Convertors — RBCFTools-package","title":"RBCFTools: 'BCFTools', 'libbcftools' and 'htslib' Wrappers and 'BCF'/'VCF' to 'Parquet' Convertors — RBCFTools-package","text":"Bundles 'htslib' 'bcftools' libraries command lines tools reading manipulating VCF/BCF files. Includes streaming facilities VCF Apache Arrow via 'nanoarrow', enabling export Arrow IPC format Parquet format using 'duckdb' including 'bcf_reader' extension. Utilities reading writing VCF/BCF files 'DuckLake' provided.","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/RBCFTools-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"RBCFTools: 'BCFTools', 'libbcftools' and 'htslib' Wrappers and 'BCF'/'VCF' to 'Parquet' Convertors — RBCFTools-package","text":"Maintainer: Sounkou Mahamane Toure sounkoutoure@gmail.com contributors: Bonfield, James K Marshall, John Danecek, Petr Li, Heng Ohan, Valeriu Whitwham, Andrew Keane, Thomas Davies, Robert M, Pierre Lindenbaum (Authors included htslib library bcftools command line tools) [copyright holder] Zilong Li zilong.dk@gmail.com (Author vcfpp library makefiles configure strategy borrowed) [copyright holder] Duckdb C API extension API authors (Authors duckdb extension API used parquet export) [copyright holder]","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/annot_tsv_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to annot-tsv Executable — annot_tsv_path","title":"Get Path to annot-tsv Executable — annot_tsv_path","text":"Returns path bundled annot-tsv executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/annot_tsv_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to annot-tsv Executable — annot_tsv_path","text":"","code":"annot_tsv_path()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/annot_tsv_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to annot-tsv Executable — annot_tsv_path","text":"character string containing path annot-tsv executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/annot_tsv_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to annot-tsv Executable — annot_tsv_path","text":"","code":"annot_tsv_path() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/bin/annot-tsv\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_build.html","id":null,"dir":"Reference","previous_headings":"","what":"Build the bcf_reader DuckDB extension — bcf_reader_build","title":"Build the bcf_reader DuckDB extension — bcf_reader_build","text":"Compiles bcf_reader extension source using package's htslib. Source files copied build directory first.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_build.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build the bcf_reader DuckDB extension — bcf_reader_build","text":"","code":"bcf_reader_build(build_dir, force = FALSE, verbose = TRUE)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_build.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build the bcf_reader DuckDB extension — bcf_reader_build","text":"build_dir Directory build extension. Source files copied extension built build_dir/build/. force Logical, force rebuild even extension exists verbose Logical, show build output","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_build.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build the bcf_reader DuckDB extension — bcf_reader_build","text":"Path built extension file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_build.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build the bcf_reader DuckDB extension — bcf_reader_build","text":"","code":"if (FALSE) { # \\dontrun{ # Build in temp directory ext_path <- bcf_reader_build(tempdir())  # Build in a specific location ext_path <- bcf_reader_build(\"/tmp/bcf_reader\")  # Force rebuild ext_path <- bcf_reader_build(\"/tmp/bcf_reader\", force = TRUE) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_copy_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy bcf_reader extension source to a build directory — bcf_reader_copy_source","title":"Copy bcf_reader extension source to a build directory — bcf_reader_copy_source","text":"Copies extension source files package specified directory building. necessary installed package directory typically read-.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_copy_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy bcf_reader extension source to a build directory — bcf_reader_copy_source","text":"","code":"bcf_reader_copy_source(dest_dir)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_copy_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy bcf_reader extension source to a build directory — bcf_reader_copy_source","text":"dest_dir Directory copy source files.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_copy_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copy bcf_reader extension source to a build directory — bcf_reader_copy_source","text":"Invisible path destination directory","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_copy_source.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Copy bcf_reader extension source to a build directory — bcf_reader_copy_source","text":"","code":"if (FALSE) { # \\dontrun{ # Copy to temp directory build_dir <- bcf_reader_copy_source(tempdir())  # Copy to a specific location build_dir <- bcf_reader_copy_source(\"/tmp/bcf_reader_build\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_source_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the source directory for bcf_reader extension in the package — bcf_reader_source_dir","title":"Get the source directory for bcf_reader extension in the package — bcf_reader_source_dir","text":"Get source directory bcf_reader extension package","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_source_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the source directory for bcf_reader extension in the package — bcf_reader_source_dir","text":"","code":"bcf_reader_source_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcf_reader_source_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the source directory for bcf_reader extension in the package — bcf_reader_source_dir","text":"Character string path extension source directory","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_bin_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to bcftools Binary Directory — bcftools_bin_dir","title":"Get Path to bcftools Binary Directory — bcftools_bin_dir","text":"Returns path directory containing bcftools related scripts.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_bin_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to bcftools Binary Directory — bcftools_bin_dir","text":"","code":"bcftools_bin_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_bin_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to bcftools Binary Directory — bcftools_bin_dir","text":"character string containing path bcftools bin directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_bin_dir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Path to bcftools Binary Directory — bcftools_bin_dir","text":"directory contains following tools: bcftools - Main bcftools executable color-chrs.pl - Chromosome coloring script gff2gff - GFF conversion tool gff2gff.py - GFF conversion Python script guess-ploidy.py - Ploidy guessing script plot-roh.py - ROH plotting script plot-vcfstats - VCF statistics plotting script roh-viz - ROH visualization tool run-roh.pl - ROH analysis script vcfutils.pl - VCF utilities script vrfs-variances - Variant frequency variances tool","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_bin_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to bcftools Binary Directory — bcftools_bin_dir","text":"","code":"bcftools_bin_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/bcftools/bin\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_lib_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get bcftools Library Directory — bcftools_lib_dir","title":"Get bcftools Library Directory — bcftools_lib_dir","text":"Returns path bcftools library files use linking.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_lib_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get bcftools Library Directory — bcftools_lib_dir","text":"","code":"bcftools_lib_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_lib_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get bcftools Library Directory — bcftools_lib_dir","text":"character string containing path bcftools lib directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_lib_dir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get bcftools Library Directory — bcftools_lib_dir","text":"directory contains libbcftools.(static) libbcftools.(shared) libraries.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_lib_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get bcftools Library Directory — bcftools_lib_dir","text":"","code":"bcftools_lib_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/bcftools/lib\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_libs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Linker Flags for bcftools Library — bcftools_libs","title":"Get Linker Flags for bcftools Library — bcftools_libs","text":"Returns linker flags needed link bcftools library.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_libs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Linker Flags for bcftools Library — bcftools_libs","text":"","code":"bcftools_libs()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_libs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Linker Flags for bcftools Library — bcftools_libs","text":"character string containing linker flags including -L library path -l library name.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_libs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Linker Flags for bcftools Library — bcftools_libs","text":"Note bcftools library also depends htslib, typically need include bcftools_libs() htslib_libs() linker flags.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_libs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Linker Flags for bcftools Library — bcftools_libs","text":"","code":"bcftools_libs() #> [1] \"-L/home/runner/work/_temp/Library/RBCFTools/bcftools/lib -lbcftools\" # Full linking: paste(RBCFTools::bcftools_libs(), RBCFTools::htslib_libs())"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to bcftools Executable — bcftools_path","title":"Get Path to bcftools Executable — bcftools_path","text":"Returns path bundled bcftools executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to bcftools Executable — bcftools_path","text":"","code":"bcftools_path()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to bcftools Executable — bcftools_path","text":"character string containing path bcftools executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to bcftools Executable — bcftools_path","text":"","code":"bcftools_path() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/bcftools/bin/bcftools\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_plugins_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to bcftools Plugins Directory — bcftools_plugins_dir","title":"Get Path to bcftools Plugins Directory — bcftools_plugins_dir","text":"Returns path directory containing bcftools plugins.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_plugins_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to bcftools Plugins Directory — bcftools_plugins_dir","text":"","code":"bcftools_plugins_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_plugins_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to bcftools Plugins Directory — bcftools_plugins_dir","text":"character string containing path bcftools plugins directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_plugins_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to bcftools Plugins Directory — bcftools_plugins_dir","text":"","code":"bcftools_plugins_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/bcftools/libexec/bcftools\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_tools.html","id":null,"dir":"Reference","previous_headings":"","what":"List Available bcftools Scripts — bcftools_tools","title":"List Available bcftools Scripts — bcftools_tools","text":"Lists available scripts tools bcftools bin directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_tools.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Available bcftools Scripts — bcftools_tools","text":"","code":"bcftools_tools()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_tools.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Available bcftools Scripts — bcftools_tools","text":"character vector available tool names.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_tools.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Available bcftools Scripts — bcftools_tools","text":"","code":"bcftools_tools() #>  [1] \"bcftools\"        \"color-chrs.pl\"   \"gff2gff\"         \"gff2gff.py\"      #>  [5] \"guess-ploidy.py\" \"plot-roh.py\"     \"plot-vcfstats\"   \"roh-viz\"         #>  [9] \"run-roh.pl\"      \"vcfutils.pl\"     \"vrfs-variances\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Get bcftools Version — bcftools_version","title":"Get bcftools Version — bcftools_version","text":"Returns version string bundled bcftools library.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get bcftools Version — bcftools_version","text":"","code":"bcftools_version()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get bcftools Version — bcftools_version","text":"character string containing bcftools version.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bcftools_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get bcftools Version — bcftools_version","text":"","code":"bcftools_version() #> [1] \"1.23\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bgzip_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to bgzip Executable — bgzip_path","title":"Get Path to bgzip Executable — bgzip_path","text":"Returns path bundled bgzip executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bgzip_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to bgzip Executable — bgzip_path","text":"","code":"bgzip_path()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bgzip_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to bgzip Executable — bgzip_path","text":"character string containing path bgzip executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/bgzip_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to bgzip Executable — bgzip_path","text":"","code":"bgzip_path() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/bin/bgzip\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake.html","id":null,"dir":"Reference","previous_headings":"","what":"DuckLake helpers for VCF/BCF ETL — ducklake","title":"DuckLake helpers for VCF/BCF ETL — ducklake","text":"Utilities load DuckLake extension, attach lake (local S3-backed), configure S3 secrets, write variants using either direct DuckDB insert parallel Parquet conversion.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_attach.html","id":null,"dir":"Reference","previous_headings":"","what":"Attach a DuckLake catalog (legacy function) — ducklake_attach","title":"Attach a DuckLake catalog (legacy function) — ducklake_attach","text":"Attach DuckLake catalog (legacy function)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_attach.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Attach a DuckLake catalog (legacy function) — ducklake_attach","text":"","code":"ducklake_attach(   con,   metadata_path,   data_path,   alias = \"ducklake\",   read_only = FALSE,   create_if_missing = TRUE,   extra_options = list() )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_attach.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Attach a DuckLake catalog (legacy function) — ducklake_attach","text":"con DuckDB connection DuckLake loaded. metadata_path Path/URI DuckLake metadata DB (without ducklake: prefix). data_path Path/URI table data (Parquet files). alias Schema alias attach . Default: \"ducklake\". read_only Logical, open lake read-. Default: FALSE. create_if_missing Logical, create metadata DB missing. Default: TRUE. extra_options Named list additional ATTACH options (e.g., list(METADATA_CATALOG = \"meta\")).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_attach.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Attach a DuckLake catalog (legacy function) — ducklake_attach","text":"Invisible NULL.","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_connect_catalog.html","id":null,"dir":"Reference","previous_headings":"","what":"Connect to a DuckLake catalog with abstracted backend support — ducklake_connect_catalog","title":"Connect to a DuckLake catalog with abstracted backend support — ducklake_connect_catalog","text":"Connect DuckLake catalog abstracted backend support","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_connect_catalog.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Connect to a DuckLake catalog with abstracted backend support — ducklake_connect_catalog","text":"","code":"ducklake_connect_catalog(   con,   backend = c(\"duckdb\", \"sqlite\", \"postgresql\", \"mysql\"),   connection_string = NULL,   data_path = NULL,   alias = \"ducklake\",   secret_name = NULL,   read_only = FALSE,   create_if_missing = TRUE,   extra_options = list() )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_connect_catalog.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Connect to a DuckLake catalog with abstracted backend support — ducklake_connect_catalog","text":"con DuckDB connection DuckLake loaded. backend Database backend type (\"duckdb\", \"sqlite\", \"postgresql\", \"mysql\"). connection_string Database connection string (format depends backend). data_path Path/URI table data (Parquet files). Required new lakes. alias Schema alias attach . Default: \"ducklake\". secret_name Optional secret name use instead direct connection parameters. read_only Logical, open lake read-. Default: FALSE. create_if_missing Logical, create metadata DB missing. Default: TRUE. extra_options Named list additional ATTACH options.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_connect_catalog.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Connect to a DuckLake catalog with abstracted backend support — ducklake_connect_catalog","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_catalog_secret.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a DuckLake catalog secret for database credentials — ducklake_create_catalog_secret","title":"Create a DuckLake catalog secret for database credentials — ducklake_create_catalog_secret","text":"Create DuckLake catalog secret database credentials","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_catalog_secret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a DuckLake catalog secret for database credentials — ducklake_create_catalog_secret","text":"","code":"ducklake_create_catalog_secret(   con,   name = \"ducklake_catalog\",   backend = c(\"duckdb\", \"sqlite\", \"postgresql\", \"mysql\"),   connection_string,   data_path = NULL,   metadata_parameters = list(),   persistent = FALSE )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_catalog_secret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a DuckLake catalog secret for database credentials — ducklake_create_catalog_secret","text":"con DuckDB connection. name Secret name (identifier). Default: \"ducklake_catalog\". backend Database backend type (\"duckdb\", \"sqlite\", \"postgresql\", \"mysql\"). connection_string Database connection string (without ducklake: prefix). data_path Default data path catalog. Optional. metadata_parameters Named list additional metadata parameters. persistent Logical, create persistent secret. Default: FALSE.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_catalog_secret.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a DuckLake catalog secret for database credentials — ducklake_create_catalog_secret","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_s3_secret.html","id":null,"dir":"Reference","previous_headings":"","what":"Create or replace an S3 secret for DuckLake — ducklake_create_s3_secret","title":"Create or replace an S3 secret for DuckLake — ducklake_create_s3_secret","text":"Create replace S3 secret DuckLake","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_s3_secret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create or replace an S3 secret for DuckLake — ducklake_create_s3_secret","text":"","code":"ducklake_create_s3_secret(   con,   name = \"ducklake_s3\",   key_id,   secret,   endpoint = NULL,   region = NULL,   use_ssl = TRUE,   url_style = \"path\",   session_token = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_s3_secret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create or replace an S3 secret for DuckLake — ducklake_create_s3_secret","text":"con DuckDB connection. name Secret name (identifier). Default: \"ducklake_s3\". key_id S3 key ID. secret S3 secret key. endpoint Optional S3-compatible endpoint (e.g., \"s3.us-east-1.amazonaws.com\" \"minio:9000\"). region Optional region. use_ssl Logical, whether use SSL. Default: TRUE. url_style URL style (\"path\" \"virtual_host\"). Default: \"path\". session_token Optional session token.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_create_s3_secret.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create or replace an S3 secret for DuckLake — ducklake_create_s3_secret","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_current_snapshot.html","id":null,"dir":"Reference","previous_headings":"","what":"Get current snapshot ID — ducklake_current_snapshot","title":"Get current snapshot ID — ducklake_current_snapshot","text":"Get current snapshot ID","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_current_snapshot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get current snapshot ID — ducklake_current_snapshot","text":"","code":"ducklake_current_snapshot(con, catalog = \"lake\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_current_snapshot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get current snapshot ID — ducklake_current_snapshot","text":"con DuckDB connection DuckLake attached. catalog DuckLake catalog name.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_current_snapshot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get current snapshot ID — ducklake_current_snapshot","text":"Integer snapshot ID.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_mc.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a static MinIO client (mc) binary — ducklake_download_mc","title":"Download a static MinIO client (mc) binary — ducklake_download_mc","text":"Download static MinIO client (mc) binary","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_mc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a static MinIO client (mc) binary — ducklake_download_mc","text":"","code":"ducklake_download_mc(dest_dir = tempdir(), url = NULL, filename = \"mc\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_mc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a static MinIO client (mc) binary — ducklake_download_mc","text":"dest_dir Destination directory (created missing). url Optional download URL. Defaults mc Linux build host arch. filename Output filename. Defaults \"mc\".","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_mc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a static MinIO client (mc) binary — ducklake_download_mc","text":"Path downloaded binary.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_minio.html","id":null,"dir":"Reference","previous_headings":"","what":"Download a static MinIO server binary — ducklake_download_minio","title":"Download a static MinIO server binary — ducklake_download_minio","text":"Download static MinIO server binary","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_minio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download a static MinIO server binary — ducklake_download_minio","text":"","code":"ducklake_download_minio(dest_dir = tempdir(), url = NULL, filename = \"minio\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_minio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download a static MinIO server binary — ducklake_download_minio","text":"dest_dir Destination directory (created missing). url Optional download URL. Defaults MinIO Linux build host arch. filename Output filename. Defaults \"minio\".","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_download_minio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download a static MinIO server binary — ducklake_download_minio","text":"Path downloaded binary.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_drop_secret.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop a DuckLake catalog secret — ducklake_drop_secret","title":"Drop a DuckLake catalog secret — ducklake_drop_secret","text":"Drop DuckLake catalog secret","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_drop_secret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop a DuckLake catalog secret — ducklake_drop_secret","text":"","code":"ducklake_drop_secret(con, name)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_drop_secret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop a DuckLake catalog secret — ducklake_drop_secret","text":"con DuckDB connection. name Secret name drop.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_drop_secret.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop a DuckLake catalog secret — ducklake_drop_secret","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_files.html","id":null,"dir":"Reference","previous_headings":"","what":"List files managed by DuckLake for a table — ducklake_list_files","title":"List files managed by DuckLake for a table — ducklake_list_files","text":"List files managed DuckLake table","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List files managed by DuckLake for a table — ducklake_list_files","text":"","code":"ducklake_list_files(con, catalog = \"lake\", table, schema = \"main\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List files managed by DuckLake for a table — ducklake_list_files","text":"con DuckDB connection DuckLake attached. catalog DuckLake catalog name. table Table name. schema Schema name (default \"main\").","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_files.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List files managed by DuckLake for a table — ducklake_list_files","text":"Data frame file information.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_secrets.html","id":null,"dir":"Reference","previous_headings":"","what":"List existing DuckLake catalog secrets — ducklake_list_secrets","title":"List existing DuckLake catalog secrets — ducklake_list_secrets","text":"List existing DuckLake catalog secrets","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_secrets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List existing DuckLake catalog secrets — ducklake_list_secrets","text":"","code":"ducklake_list_secrets(con)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_secrets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List existing DuckLake catalog secrets — ducklake_list_secrets","text":"con DuckDB connection.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_list_secrets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List existing DuckLake catalog secrets — ducklake_list_secrets","text":"Data frame columns: name, type, metadata_path, data_path.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Load the DuckLake extension — ducklake_load","title":"Load the DuckLake extension — ducklake_load","text":"Load DuckLake extension","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load the DuckLake extension — ducklake_load","text":"","code":"ducklake_load(con, install = TRUE)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load the DuckLake extension — ducklake_load","text":"con DuckDB connection. install Logical, attempt INSTALL ducklake loading. Defaults TRUE.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load the DuckLake extension — ducklake_load","text":"connection (invisibly).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load_vcf.html","id":null,"dir":"Reference","previous_headings":"","what":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","title":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","text":"Converts VCF/BCF Parquet using fast bcf_reader extension, registers Parquet file DuckLake catalog table.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load_vcf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","text":"","code":"ducklake_load_vcf(   con,   table,   vcf_path,   extension_path,   output_path = NULL,   threads = parallel::detectCores(),   compression = \"zstd\",   row_group_size = 100000L,   region = NULL,   columns = NULL,   overwrite = FALSE,   allow_evolution = FALSE,   tidy_format = FALSE,   partition_by = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load_vcf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","text":"con DuckDB connection DuckLake attached. table Target table name (optionally qualified, e.g., \"lake.variants\"). vcf_path Path/URI VCF/BCF file. extension_path Path bcf_reader.duckdb_extension (required). output_path Optional Parquet output path. NULL, uses DuckLake's DATA_PATH. threads Number threads conversion. compression Parquet compression codec. row_group_size Parquet row group size. region Optional region filter (e.g., \"chr1:1000-2000\"). columns Optional character vector columns include. overwrite Logical, drop existing table first. allow_evolution Logical, evolve table schema adding new columns VCF. Default: FALSE. TRUE, new columns found VCF added via ALTER TABLE insertion, making columns queryable. Useful combining VCFs different annotations (e.g., VEP columns) different samples (FORMAT_*_SampleName). tidy_format Logical, TRUE exports data tidy (long) format one row per variant-sample combination SAMPLE_ID column. Default FALSE. Ideal cohort analysis combining multiple single-sample VCFs. partition_by Optional character vector columns partition (Hive-style). Creates directory structure like output_dir/SAMPLE_ID=HG00098/data_0.parquet. Note: DuckLake registration currently requires single Parquet files; using partition_by, output_path point partition directory files registered separately.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load_vcf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","text":"Invisibly returns path created Parquet file.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load_vcf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","text":"recommended function loading VCF data DuckLake. uses bcf_reader DuckDB extension fast VCF→Parquet conversion, significantly faster nanoarrow streaming path. Workflow: VCF → Parquet via vcf_to_parquet_duckdb() (bcf_reader) Register Parquet DuckLake catalog Schema Evolution (allow_evolution = TRUE): loading multiple VCFs different schemas (e.g., different samples different annotation fields), enable allow_evolution automatically add new columns table schema. uses DuckLake's ALTER TABLE ADD COLUMN preserves existing data files without rewriting. Tidy Format (tidy_format = TRUE): building cohort tables multiple single-sample VCFs, use tidy_format = TRUE get one row per variant-sample combination SAMPLE_ID column. format ideal downstream analysis MERGE/UPSERT operations DuckLake tables. Partitioning (partition_by): using partition_by, output Hive-partitioned directory structure. useful large cohorts want efficient per-sample queries. DuckDB auto-generates Bloom filters VARCHAR columns like SAMPLE_ID. Note: DuckLake, partitioned output requires manual file registration.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_load_vcf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load VCF into DuckLake (ETL + Registration) — ducklake_load_vcf","text":"","code":"if (FALSE) { # \\dontrun{ # Build extension ext_path <- bcf_reader_build(tempdir())  # Setup DuckLake con <- duckdb::dbConnect(duckdb::duckdb()) ducklake_load(con) ducklake_attach(con, \"catalog.ducklake\", \"/data/parquet/\", alias = \"lake\") DBI::dbExecute(con, \"USE lake\")  # Load first VCF ducklake_load_vcf(con, \"variants\", \"sample1.vcf.gz\", ext_path, threads = 8)  # Load second VCF with different annotations, evolving schema ducklake_load_vcf(con, \"variants\", \"sample2_vep.vcf.gz\", ext_path,   allow_evolution = TRUE )  # Load VCF in tidy format (one row per variant-sample) ducklake_load_vcf(con, \"variants_tidy\", \"cohort.vcf.gz\", ext_path,   tidy_format = TRUE )  # Query - all columns from both VCFs are available DBI::dbGetQuery(con, \"SELECT CHROM, COUNT(*) FROM variants GROUP BY CHROM\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_merge.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge/upsert data into a DuckLake table — ducklake_merge","title":"Merge/upsert data into a DuckLake table — ducklake_merge","text":"Merge/upsert data DuckLake table","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_merge.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge/upsert data into a DuckLake table — ducklake_merge","text":"","code":"ducklake_merge(   con,   target,   source,   on_cols,   when_matched = \"UPDATE\",   when_not_matched = \"INSERT\",   update_cols = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_merge.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge/upsert data into a DuckLake table — ducklake_merge","text":"con DuckDB connection DuckLake attached. target Target table name. source Source table/query. on_cols Column(s) match . when_matched Action matched: \"UPDATE\", \"DELETE\", NULL. when_not_matched Action matched: \"INSERT\" NULL. update_cols Columns update (NULL = columns).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_merge.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge/upsert data into a DuckLake table — ducklake_merge","text":"Number rows affected.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Get DuckLake configuration options — ducklake_options","title":"Get DuckLake configuration options — ducklake_options","text":"Get DuckLake configuration options","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get DuckLake configuration options — ducklake_options","text":"","code":"ducklake_options(con, catalog = \"lake\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get DuckLake configuration options — ducklake_options","text":"con DuckDB connection DuckLake attached. catalog DuckLake catalog name.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get DuckLake configuration options — ducklake_options","text":"Data frame current options.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_parse_connection_string.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse DuckLake connection string into components — ducklake_parse_connection_string","title":"Parse DuckLake connection string into components — ducklake_parse_connection_string","text":"Parse DuckLake connection string components","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_parse_connection_string.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse DuckLake connection string into components — ducklake_parse_connection_string","text":"","code":"ducklake_parse_connection_string(connection_string)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_parse_connection_string.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse DuckLake connection string into components — ducklake_parse_connection_string","text":"connection_string DuckLake connection string (e.g., \"ducklake:path//catalog.ducklake\").","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_parse_connection_string.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse DuckLake connection string into components — ducklake_parse_connection_string","text":"Named list components: backend, metadata_path, data_path (specified).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_query_snapshot.html","id":null,"dir":"Reference","previous_headings":"","what":"Query table at a specific snapshot (time travel) — ducklake_query_snapshot","title":"Query table at a specific snapshot (time travel) — ducklake_query_snapshot","text":"Query table specific snapshot (time travel)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_query_snapshot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query table at a specific snapshot (time travel) — ducklake_query_snapshot","text":"","code":"ducklake_query_snapshot(con, table, snapshot_id, query = \"SELECT * FROM tbl\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_query_snapshot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query table at a specific snapshot (time travel) — ducklake_query_snapshot","text":"con DuckDB connection DuckLake attached. table Table name. snapshot_id Snapshot version query. query SQL query (use 'tbl' table alias).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_query_snapshot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query table at a specific snapshot (time travel) — ducklake_query_snapshot","text":"Query result data frame.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_register_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","title":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","text":"Adds Parquet files already exist (prior ETL) DuckLake table. catalog-operation; data files copied moved.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_register_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","text":"","code":"ducklake_register_parquet(   con,   table,   parquet_files,   create_table = TRUE,   allow_missing = FALSE,   ignore_extra_columns = FALSE,   allow_evolution = FALSE )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_register_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","text":"con DuckDB connection DuckLake attached. table Target table name (optionally qualified, e.g., \"lake.variants\"). parquet_files Character vector Parquet file paths/URIs. create_table Logical, create table exist. Default: TRUE. TRUE, schema inferred first Parquet file. allow_missing Logical, allow missing columns (filled defaults). Default: FALSE. ignore_extra_columns Logical, ignore extra columns files. Default: FALSE. allow_evolution Logical, evolve table schema adding new columns files. Default: FALSE. TRUE, new columns found files added via ALTER TABLE registration, making columns queryable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_register_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","text":"Invisibly returns number files registered.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_register_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","text":"function uses DuckLake's ducklake_add_data_files() register external Parquet files catalog. files must already exist schema compatible target table. Schema Evolution (allow_evolution = TRUE): enabled, function compares file's schema table schema adds missing columns via ALTER TABLE ADD COLUMN registration. allows combining VCF files different annotations (e.g., VEP columns) single table columns queryable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_register_parquet.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Register existing Parquet files in a DuckLake table — ducklake_register_parquet","text":"","code":"if (FALSE) { # \\dontrun{ # Register a Parquet file created by vcf_to_parquet_duckdb() ducklake_register_parquet(con, \"variants\", \"s3://bucket/variants.parquet\")  # Register with schema evolution (add new columns from file) ducklake_register_parquet(con, \"variants\", \"s3://bucket/vep_variants.parquet\",   allow_evolution = TRUE ) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_commit_message.html","id":null,"dir":"Reference","previous_headings":"","what":"Set commit message for current transaction — ducklake_set_commit_message","title":"Set commit message for current transaction — ducklake_set_commit_message","text":"Must called within transaction (BEGIN/COMMIT block).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_commit_message.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set commit message for current transaction — ducklake_set_commit_message","text":"","code":"ducklake_set_commit_message(   con,   catalog = \"lake\",   author,   message,   extra_info = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_commit_message.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set commit message for current transaction — ducklake_set_commit_message","text":"con DuckDB connection DuckLake attached. catalog DuckLake catalog name. author Author name. message Commit message. extra_info Optional JSON string extra metadata.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_commit_message.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set commit message for current transaction — ducklake_set_commit_message","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_option.html","id":null,"dir":"Reference","previous_headings":"","what":"Set DuckLake configuration option — ducklake_set_option","title":"Set DuckLake configuration option — ducklake_set_option","text":"Set DuckLake configuration option","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_option.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set DuckLake configuration option — ducklake_set_option","text":"","code":"ducklake_set_option(   con,   catalog = \"lake\",   option,   value,   schema = NULL,   table_name = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_option.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set DuckLake configuration option — ducklake_set_option","text":"con DuckDB connection DuckLake attached. catalog DuckLake catalog name. option Option name (e.g., \"parquet_compression\", \"parquet_row_group_size\"). value Option value. schema Optional schema scope. table_name Optional table scope.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_option.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set DuckLake configuration option — ducklake_set_option","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_set_option.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set DuckLake configuration option — ducklake_set_option","text":"Common options: parquet_compression: snappy, zstd, gzip, lz4 parquet_row_group_size: rows per row group (default 122880) target_file_size: target file size compaction (default 512MB data_inlining_row_limit: max rows inline (default 0)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_snapshots.html","id":null,"dir":"Reference","previous_headings":"","what":"List DuckLake snapshots — ducklake_snapshots","title":"List DuckLake snapshots — ducklake_snapshots","text":"List DuckLake snapshots","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_snapshots.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List DuckLake snapshots — ducklake_snapshots","text":"","code":"ducklake_snapshots(con, catalog = \"lake\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_snapshots.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List DuckLake snapshots — ducklake_snapshots","text":"con DuckDB connection DuckLake attached. catalog DuckLake catalog name (alias used ATTACH).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_snapshots.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List DuckLake snapshots — ducklake_snapshots","text":"Data frame snapshot history.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_update_secret.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an existing DuckLake catalog secret — ducklake_update_secret","title":"Update an existing DuckLake catalog secret — ducklake_update_secret","text":"Update existing DuckLake catalog secret","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_update_secret.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an existing DuckLake catalog secret — ducklake_update_secret","text":"","code":"ducklake_update_secret(   con,   name,   connection_string,   data_path = NULL,   metadata_parameters = list() )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_update_secret.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an existing DuckLake catalog secret — ducklake_update_secret","text":"con DuckDB connection. name Secret name update. connection_string New database connection string. data_path New default data path. Optional. metadata_parameters New named list metadata parameters.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ducklake_update_secret.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update an existing DuckLake catalog secret — ducklake_update_secret","text":"Invisible NULL.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/format_kv_metadata_sql.html","id":null,"dir":"Reference","previous_headings":"","what":"Format metadata for DuckDB KV_METADATA clause — format_kv_metadata_sql","title":"Format metadata for DuckDB KV_METADATA clause — format_kv_metadata_sql","text":"Format metadata DuckDB KV_METADATA clause","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/format_kv_metadata_sql.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format metadata for DuckDB KV_METADATA clause — format_kv_metadata_sql","text":"","code":"format_kv_metadata_sql(metadata)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/format_kv_metadata_sql.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format metadata for DuckDB KV_METADATA clause — format_kv_metadata_sql","text":"metadata Named list key-value pairs","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/format_kv_metadata_sql.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format metadata for DuckDB KV_METADATA clause — format_kv_metadata_sql","text":"Character string KV_METADATA SQL clause","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htsfile_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to htsfile Executable — htsfile_path","title":"Get Path to htsfile Executable — htsfile_path","text":"Returns path bundled htsfile executable identifying file formats.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htsfile_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to htsfile Executable — htsfile_path","text":"","code":"htsfile_path()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htsfile_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to htsfile Executable — htsfile_path","text":"character string containing path htsfile executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htsfile_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to htsfile Executable — htsfile_path","text":"","code":"htsfile_path() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/bin/htsfile\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_bin_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to htslib Binary Directory — htslib_bin_dir","title":"Get Path to htslib Binary Directory — htslib_bin_dir","text":"Returns path directory containing htslib executables.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_bin_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to htslib Binary Directory — htslib_bin_dir","text":"","code":"htslib_bin_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_bin_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to htslib Binary Directory — htslib_bin_dir","text":"character string containing path htslib bin directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_bin_dir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Path to htslib Binary Directory — htslib_bin_dir","text":"directory contains following tools: annot-tsv - Annotate TSV files bgzip - Block gzip compression htsfile - Identify file format ref-cache - Reference sequence cache management tabix - Index query TAB-delimited files","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_bin_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to htslib Binary Directory — htslib_bin_dir","text":"","code":"htslib_bin_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/bin\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_capabilities.html","id":null,"dir":"Reference","previous_headings":"","what":"Get htslib Capabilities — htslib_capabilities","title":"Get htslib Capabilities — htslib_capabilities","text":"Returns named list capabilities bundled htslib library.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_capabilities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get htslib Capabilities — htslib_capabilities","text":"","code":"htslib_capabilities()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_capabilities.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get htslib Capabilities — htslib_capabilities","text":"named list logical values capability: configure Whether ./configure used build. plugins Whether plugins enabled. libcurl Whether libcurl support enabled. s3 Whether S3 support enabled. gcs Whether Google Cloud Storage support enabled. libdeflate Whether libdeflate compression enabled. lzma Whether LZMA compression enabled. bzip2 Whether bzip2 compression enabled. htscodecs Whether htscodecs library available.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_capabilities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get htslib Capabilities — htslib_capabilities","text":"","code":"caps <- htslib_capabilities() caps$libcurl #> [1] TRUE caps$s3 #> [1] TRUE"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_cflags.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Compiler Flags for htslib — htslib_cflags","title":"Get Compiler Flags for htslib — htslib_cflags","text":"Returns compiler flags (CFLAGS/CPPFLAGS) needed compile code uses htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_cflags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Compiler Flags for htslib — htslib_cflags","text":"","code":"htslib_cflags()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_cflags.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Compiler Flags for htslib — htslib_cflags","text":"character string containing compiler flags including -include path.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_cflags.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Compiler Flags for htslib — htslib_cflags","text":"","code":"htslib_cflags() #> [1] \"-I/home/runner/work/_temp/Library/RBCFTools/htslib/include\" # Use in Makevars: PKG_CPPFLAGS = $(shell Rscript -e \"cat(RBCFTools::htslib_cflags())\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_feature_string.html","id":null,"dir":"Reference","previous_headings":"","what":"Get htslib Feature String — htslib_feature_string","title":"Get htslib Feature String — htslib_feature_string","text":"Returns human-readable string describing enabled features htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_feature_string.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get htslib Feature String — htslib_feature_string","text":"","code":"htslib_feature_string()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_feature_string.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get htslib Feature String — htslib_feature_string","text":"character string describing enabled features.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_feature_string.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get htslib Feature String — htslib_feature_string","text":"","code":"htslib_feature_string() #> [1] \"build=configure libcurl=yes S3=yes GCS=yes libdeflate=yes lzma=yes bzip2=yes plugins=yes plugin-path=/home/runner/work/_temp/Library/RBCFTools/htslib/libexec/htslib: htscodecs=1.6.5\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Get htslib Features Bitfield — htslib_features","title":"Get htslib Features Bitfield — htslib_features","text":"Returns raw bitfield enabled features htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get htslib Features Bitfield — htslib_features","text":"","code":"htslib_features()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get htslib Features Bitfield — htslib_features","text":"integer representing feature bitfield.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get htslib Features Bitfield — htslib_features","text":"","code":"htslib_features() #> [1] 15735811"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_has_feature.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for a Specific htslib Feature — htslib_has_feature","title":"Check for a Specific htslib Feature — htslib_has_feature","text":"Checks specific feature enabled bundled htslib library.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_has_feature.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for a Specific htslib Feature — htslib_has_feature","text":"","code":"htslib_has_feature(feature_id)  HTS_FEATURE_CONFIGURE  HTS_FEATURE_PLUGINS  HTS_FEATURE_LIBCURL  HTS_FEATURE_S3  HTS_FEATURE_GCS  HTS_FEATURE_LIBDEFLATE  HTS_FEATURE_LZMA  HTS_FEATURE_BZIP2  HTS_FEATURE_HTSCODECS"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_has_feature.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Check for a Specific htslib Feature — htslib_has_feature","text":"object class integer length 1. object class integer length 1. object class integer length 1. object class integer length 1. object class integer length 1. object class integer length 1. object class integer length 1. object class integer length 1. object class integer length 1.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_has_feature.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for a Specific htslib Feature — htslib_has_feature","text":"feature_id integer feature ID. Use one HTS_FEATURE_* constants.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_has_feature.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for a Specific htslib Feature — htslib_has_feature","text":"logical value indicating feature enabled.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_has_feature.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for a Specific htslib Feature — htslib_has_feature","text":"","code":"# Check for libcurl support (feature ID 1024) htslib_has_feature(1024L) #> [1] TRUE"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_include_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get htslib Include Directory — htslib_include_dir","title":"Get htslib Include Directory — htslib_include_dir","text":"Returns path htslib header files use compilation.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_include_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get htslib Include Directory — htslib_include_dir","text":"","code":"htslib_include_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_include_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get htslib Include Directory — htslib_include_dir","text":"character string containing path htslib include directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_include_dir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get htslib Include Directory — htslib_include_dir","text":"directory contains htslib headers (e.g., htslib/hts.h, htslib/vcf.h, etc.). Use path -compiler flag compiling code uses htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_include_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get htslib Include Directory — htslib_include_dir","text":"","code":"htslib_include_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/include\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_lib_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get htslib Library Directory — htslib_lib_dir","title":"Get htslib Library Directory — htslib_lib_dir","text":"Returns path htslib library files use linking.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_lib_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get htslib Library Directory — htslib_lib_dir","text":"","code":"htslib_lib_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_lib_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get htslib Library Directory — htslib_lib_dir","text":"character string containing path htslib lib directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_lib_dir.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get htslib Library Directory — htslib_lib_dir","text":"directory contains libhts.(static) libhts.(shared) libraries. Use path -L linker flag linking htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_lib_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get htslib Library Directory — htslib_lib_dir","text":"","code":"htslib_lib_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/lib\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_libs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Linker Flags for htslib — htslib_libs","title":"Get Linker Flags for htslib — htslib_libs","text":"Returns linker flags needed link htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_libs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Linker Flags for htslib — htslib_libs","text":"","code":"htslib_libs(static = FALSE)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_libs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Linker Flags for htslib — htslib_libs","text":"static Logical. TRUE, returns flags static linking. FALSE (default), returns flags dynamic linking.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_libs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Linker Flags for htslib — htslib_libs","text":"character string containing linker flags including -L library path -l library names.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_libs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Linker Flags for htslib — htslib_libs","text":"dynamic linking, returns -L<libdir> -lhts. static linking, also includes dependent libraries: -lpthread -lz -lm -lbz2 -llzma -ldeflate.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_libs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Linker Flags for htslib — htslib_libs","text":"","code":"htslib_libs() #> [1] \"-L/home/runner/work/_temp/Library/RBCFTools/htslib/lib -lhts\" htslib_libs(static = TRUE) #> [1] \"-L/home/runner/work/_temp/Library/RBCFTools/htslib/lib -lhts -lpthread -lz -lm -lbz2 -llzma -ldeflate -ldl\" # Use in Makevars: PKG_LIBS = $(shell Rscript -e \"cat(RBCFTools::htslib_libs())\")"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_plugins_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to htslib Plugins Directory — htslib_plugins_dir","title":"Get Path to htslib Plugins Directory — htslib_plugins_dir","text":"Returns path directory containing htslib plugins (e.g., remote file access via libcurl, S3, GCS).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_plugins_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to htslib Plugins Directory — htslib_plugins_dir","text":"","code":"htslib_plugins_dir()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_plugins_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to htslib Plugins Directory — htslib_plugins_dir","text":"character string containing path htslib plugins directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_plugins_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to htslib Plugins Directory — htslib_plugins_dir","text":"","code":"htslib_plugins_dir() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/libexec/htslib\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_tools.html","id":null,"dir":"Reference","previous_headings":"","what":"List Available htslib Tools — htslib_tools","title":"List Available htslib Tools — htslib_tools","text":"Lists available tools htslib bin directory.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_tools.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Available htslib Tools — htslib_tools","text":"","code":"htslib_tools()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_tools.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Available htslib Tools — htslib_tools","text":"character vector available tool names.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_tools.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Available htslib Tools — htslib_tools","text":"","code":"htslib_tools() #> [1] \"annot-tsv\" \"bgzip\"     \"htsfile\"   \"ref-cache\" \"tabix\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Get htslib Version — htslib_version","title":"Get htslib Version — htslib_version","text":"Returns version string bundled htslib library.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get htslib Version — htslib_version","text":"","code":"htslib_version()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get htslib Version — htslib_version","text":"character string containing htslib version.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/htslib_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get htslib Version — htslib_version","text":"","code":"htslib_version() #> [1] \"1.23\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/linking_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Get All Linking Information for RBCFTools — linking_info","title":"Get All Linking Information for RBCFTools — linking_info","text":"Returns list paths flags needed linking htslib bcftools package.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/linking_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get All Linking Information for RBCFTools — linking_info","text":"","code":"linking_info()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/linking_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get All Linking Information for RBCFTools — linking_info","text":"named list following elements: htslib_include Path htslib include directory htslib_lib Path htslib library directory bcftools_lib Path bcftools library directory cflags Compiler flags htslib htslib_libs Linker flags htslib (dynamic) htslib_libs_static Linker flags htslib (static) bcftools_libs Linker flags bcftools all_libs Combined linker flags bcftools htslib","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/linking_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get All Linking Information for RBCFTools — linking_info","text":"","code":"info <- linking_info() info$cflags #> [1] \"-I/home/runner/work/_temp/Library/RBCFTools/htslib/include\" info$all_libs #> [1] \"-L/home/runner/work/_temp/Library/RBCFTools/bcftools/lib -lbcftools -L/home/runner/work/_temp/Library/RBCFTools/htslib/lib -lhts\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_kv_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Parquet key-value metadata — parquet_kv_metadata","title":"Read Parquet key-value metadata — parquet_kv_metadata","text":"Reads custom key-value metadata stored Parquet file's footer. includes full VCF header file created vcf_to_parquet_duckdb include_metadata = TRUE.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_kv_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Parquet key-value metadata — parquet_kv_metadata","text":"","code":"parquet_kv_metadata(file, con = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_kv_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Parquet key-value metadata — parquet_kv_metadata","text":"file Path Parquet file con Optional existing DuckDB connection","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_kv_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read Parquet key-value metadata — parquet_kv_metadata","text":"data frame columns: key, value. Returns empty data frame custom metadata exists.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_kv_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read Parquet key-value metadata — parquet_kv_metadata","text":"","code":"if (FALSE) { # \\dontrun{ meta <- parquet_kv_metadata(\"variants.parquet\") # Get the VCF header vcf_header <- meta[meta$key == \"vcf_header\", \"value\"] cat(vcf_header) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Parquet back to VCF/BCF format — parquet_to_vcf","title":"Convert Parquet back to VCF/BCF format — parquet_to_vcf","text":"Reconstruct VCF file Parquet data created vcf_to_parquet_duckdb. Uses VCF header stored Parquet metadata proper formatting.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Parquet back to VCF/BCF format — parquet_to_vcf","text":"","code":"parquet_to_vcf(   input_file,   output_file,   header = NULL,   index = TRUE,   con = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Parquet back to VCF/BCF format — parquet_to_vcf","text":"input_file Path input Parquet file (must VCF metadata) output_file Path output VCF/VCF.GZ/BCF file. Format determined extension. header Optional VCF header string. NULL (default), reads Parquet metadata. index Logical, TRUE creates tabix/CSI index output. Default TRUE. con Optional existing DuckDB connection","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Parquet back to VCF/BCF format — parquet_to_vcf","text":"Invisible path output file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Parquet back to VCF/BCF format — parquet_to_vcf","text":"","code":"if (FALSE) { # \\dontrun{ # Round-trip: VCF -> Parquet -> VCF vcf_file <- system.file(\"extdata\", \"1000G_3samples.vcf.gz\", package = \"RBCFTools\") ext_path <- bcf_reader_build(tempdir(), verbose = FALSE)  # Convert to Parquet (with metadata) parquet_file <- tempfile(fileext = \".parquet\") vcf_to_parquet_duckdb(vcf_file, parquet_file, ext_path)  # Convert back to VCF vcf_out <- tempfile(fileext = \".vcf.gz\") parquet_to_vcf(parquet_file, vcf_out) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf_tidy.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert tidy format Parquet back to VCF — parquet_to_vcf_tidy","title":"Convert tidy format Parquet back to VCF — parquet_to_vcf_tidy","text":"Convert tidy format Parquet back VCF","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf_tidy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert tidy format Parquet back to VCF — parquet_to_vcf_tidy","text":"","code":"parquet_to_vcf_tidy(input_file, output_file, header, index, con, meta)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert wide format Parquet back to VCF — parquet_to_vcf_wide","title":"Convert wide format Parquet back to VCF — parquet_to_vcf_wide","text":"Convert wide format Parquet back VCF","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/parquet_to_vcf_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert wide format Parquet back to VCF — parquet_to_vcf_wide","text":"","code":"parquet_to_vcf_wide(input_file, output_file, header, index, con)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print.vcf_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for vcf_duckdb objects — print.vcf_duckdb","title":"Print method for vcf_duckdb objects — print.vcf_duckdb","text":"Print method vcf_duckdb objects","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print.vcf_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for vcf_duckdb objects — print.vcf_duckdb","text":"","code":"# S3 method for class 'vcf_duckdb' print(x, ...)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print.vcf_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for vcf_duckdb objects — print.vcf_duckdb","text":"x vcf_duckdb object ... Additional arguments (ignored)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print_makevars_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Makevars Configuration for LinkingTo — print_makevars_config","title":"Print Makevars Configuration for LinkingTo — print_makevars_config","text":"Prints example Makevars configuration can used packages want link htslib /bcftools via LinkingTo.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print_makevars_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Makevars Configuration for LinkingTo — print_makevars_config","text":"","code":"print_makevars_config(use_bcftools = FALSE, static = FALSE)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print_makevars_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Makevars Configuration for LinkingTo — print_makevars_config","text":"use_bcftools Logical. TRUE, includes bcftools library flags. Default FALSE (htslib ). static Logical. TRUE, uses static linking flags. Default FALSE.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print_makevars_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Makevars Configuration for LinkingTo — print_makevars_config","text":"Invisibly returns Makevars text character string.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/print_makevars_config.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Makevars Configuration for LinkingTo — print_makevars_config","text":"","code":"# Print Makevars for htslib only print_makevars_config() #> # Add to your package's src/Makevars or src/Makevars.in #> # Generated by RBCFTools::print_makevars_config() #>  #> PKG_CPPFLAGS = -I/home/runner/work/_temp/Library/RBCFTools/htslib/include #> PKG_LIBS = -L/home/runner/work/_temp/Library/RBCFTools/htslib/lib -lhts -Wl,--disable-new-dtags -Wl,-rpath,'$$ORIGIN/../htslib/lib'  # Print Makevars for both bcftools and htslib print_makevars_config(use_bcftools = TRUE) #> # Add to your package's src/Makevars or src/Makevars.in #> # Generated by RBCFTools::print_makevars_config() #>  #> PKG_CPPFLAGS = -I/home/runner/work/_temp/Library/RBCFTools/htslib/include #> PKG_LIBS = -L/home/runner/work/_temp/Library/RBCFTools/bcftools/lib -lbcftools -L/home/runner/work/_temp/Library/RBCFTools/htslib/lib -lhts -Wl,--disable-new-dtags -Wl,-rpath,'$$ORIGIN/../bcftools/lib' -Wl,-rpath,'$$ORIGIN/../htslib/lib'"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ref_cache_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to ref-cache Executable — ref_cache_path","title":"Get Path to ref-cache Executable — ref_cache_path","text":"Returns path bundled ref-cache executable reference sequence cache management.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ref_cache_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to ref-cache Executable — ref_cache_path","text":"","code":"ref_cache_path()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ref_cache_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to ref-cache Executable — ref_cache_path","text":"character string containing path ref-cache executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/ref_cache_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to ref-cache Executable — ref_cache_path","text":"","code":"ref_cache_path() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/bin/ref-cache\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/setup_hts_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup Environment for Remote File Access — setup_hts_env","title":"Setup Environment for Remote File Access — setup_hts_env","text":"Sets HTS_PATH environment variable point bundled htslib plugins directory. required S3, GCS, remote file access via libcurl.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/setup_hts_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup Environment for Remote File Access — setup_hts_env","text":"","code":"setup_hts_env()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/setup_hts_env.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup Environment for Remote File Access — setup_hts_env","text":"Invisibly returns previous value HTS_PATH (NA unset).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/setup_hts_env.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Setup Environment for Remote File Access — setup_hts_env","text":"Call function using bcftools/htslib tools remote URLs (s3://, gs://, http://, etc.). function sets HTS_PATH package's plugin directory htslib can find hfile_libcurl.hfile_gcs..","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/setup_hts_env.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setup Environment for Remote File Access — setup_hts_env","text":"","code":"setup_hts_env() # Now bcftools can access S3 URLs"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/tabix_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Path to tabix Executable — tabix_path","title":"Get Path to tabix Executable — tabix_path","text":"Returns path bundled tabix executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/tabix_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Path to tabix Executable — tabix_path","text":"","code":"tabix_path()"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/tabix_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Path to tabix Executable — tabix_path","text":"character string containing path tabix executable.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/tabix_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Path to tabix Executable — tabix_path","text":"","code":"tabix_path() #> [1] \"/home/runner/work/_temp/Library/RBCFTools/htslib/bin/tabix\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_arrow_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Arrow schema for a VCF file — vcf_arrow_schema","title":"Get the Arrow schema for a VCF file — vcf_arrow_schema","text":"Reads header VCF/BCF file returns corresponding Arrow schema.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_arrow_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Arrow schema for a VCF file — vcf_arrow_schema","text":"","code":"vcf_arrow_schema(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_arrow_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Arrow schema for a VCF file — vcf_arrow_schema","text":"filename Path VCF BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_arrow_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Arrow schema for a VCF file — vcf_arrow_schema","text":"nanoarrow_schema object","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_close_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Close a VCF DuckDB connection — vcf_close_duckdb","title":"Close a VCF DuckDB connection — vcf_close_duckdb","text":"Properly closes DuckDB connection opened vcf_open_duckdb.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_close_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Close a VCF DuckDB connection — vcf_close_duckdb","text":"","code":"vcf_close_duckdb(vcf, shutdown = TRUE)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_close_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Close a VCF DuckDB connection — vcf_close_duckdb","text":"vcf vcf_duckdb object returned vcf_open_duckdb shutdown Logical, whether shutdown DuckDB instance (default: TRUE)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_close_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Close a VCF DuckDB connection — vcf_close_duckdb","text":"Invisible NULL","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_close_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Close a VCF DuckDB connection — vcf_close_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path) # ... do queries ... vcf_close_duckdb(vcf) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Count variants in a VCF/BCF file — vcf_count_duckdb","title":"Count variants in a VCF/BCF file — vcf_count_duckdb","text":"Fast variant count using DuckDB projection pushdown.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count variants in a VCF/BCF file — vcf_count_duckdb","text":"","code":"vcf_count_duckdb(   file,   extension_path = NULL,   region = NULL,   tidy_format = FALSE,   con = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count variants in a VCF/BCF file — vcf_count_duckdb","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. region Optional genomic region indexed files tidy_format Logical, TRUE counts rows tidy format (one per variant-sample). Default FALSE returns count variants. con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Count variants in a VCF/BCF file — vcf_count_duckdb","text":"Integer count variants (variant-sample combinations tidy_format=TRUE)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Count variants in a VCF/BCF file — vcf_count_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir()) vcf_count_duckdb(\"variants.vcf.gz\", ext_path) vcf_count_duckdb(\"variants.vcf.gz\", ext_path, region = \"chr22\")  # Count variant-sample rows (variants * samples) vcf_count_duckdb(\"cohort.vcf.gz\", ext_path, tidy_format = TRUE) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_per_contig.html","id":null,"dir":"Reference","previous_headings":"","what":"Get variant counts per contig using bcftools — vcf_count_per_contig","title":"Get variant counts per contig using bcftools — vcf_count_per_contig","text":"Uses bcftools index –stats get per-contig variant counts. Requires indexed file.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_per_contig.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get variant counts per contig using bcftools — vcf_count_per_contig","text":"","code":"vcf_count_per_contig(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_per_contig.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get variant counts per contig using bcftools — vcf_count_per_contig","text":"filename Path VCF/BCF file (must indexed)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_per_contig.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get variant counts per contig using bcftools — vcf_count_per_contig","text":"Named integer vector (names = contigs, values = variant counts)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_per_contig.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get variant counts per contig using bcftools — vcf_count_per_contig","text":"","code":"if (FALSE) { # \\dontrun{ counts <- vcf_count_per_contig(\"variants.vcf.gz\") # chr1: 12345, chr2: 23456, ... } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_variants.html","id":null,"dir":"Reference","previous_headings":"","what":"Get number of variants using bcftools — vcf_count_variants","title":"Get number of variants using bcftools — vcf_count_variants","text":"Uses bundled bcftools count variants efficiently. indexed files, fast. Can also count per-chromosome.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_variants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get number of variants using bcftools — vcf_count_variants","text":"","code":"vcf_count_variants(filename, region = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_variants.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get number of variants using bcftools — vcf_count_variants","text":"filename Path VCF/BCF file region Optional region string (e.g., \"chr1\" \"chr1:1-1000\")","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_variants.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get number of variants using bcftools — vcf_count_variants","text":"Integer count variants","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_count_variants.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get number of variants using bcftools — vcf_count_variants","text":"","code":"if (FALSE) { # \\dontrun{ # Total variants n <- vcf_count_variants(\"variants.vcf.gz\")  # Variants on chr1 n_chr1 <- vcf_count_variants(\"variants.vcf.gz\", region = \"chr1\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"DuckDB VCF/BCF Query Utilities — vcf_duckdb","title":"DuckDB VCF/BCF Query Utilities — vcf_duckdb","text":"Functions querying VCF/BCF files using DuckDB bcf_reader extension.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_duckdb_connect.html","id":null,"dir":"Reference","previous_headings":"","what":"Setup DuckDB connection with bcf_reader extension loaded — vcf_duckdb_connect","title":"Setup DuckDB connection with bcf_reader extension loaded — vcf_duckdb_connect","text":"Creates DuckDB connection loads bcf_reader extension VCF/BCF queries.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_duckdb_connect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Setup DuckDB connection with bcf_reader extension loaded — vcf_duckdb_connect","text":"","code":"vcf_duckdb_connect(   extension_path,   dbdir = \":memory:\",   read_only = FALSE,   config = list() )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_duckdb_connect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Setup DuckDB connection with bcf_reader extension loaded — vcf_duckdb_connect","text":"extension_path Path bcf_reader.duckdb_extension file. Must explicitly provided. dbdir Database directory. Default \":memory:\" -memory database. read_only Logical, whether open read-mode. Default FALSE. config Named list DuckDB configuration options.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_duckdb_connect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Setup DuckDB connection with bcf_reader extension loaded — vcf_duckdb_connect","text":"DuckDB connection object bcf_reader extension loaded","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_duckdb_connect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Setup DuckDB connection with bcf_reader extension loaded — vcf_duckdb_connect","text":"","code":"if (FALSE) { # \\dontrun{ # First build the extension ext_path <- bcf_reader_build(tempdir())  # Then connect con <- vcf_duckdb_connect(ext_path) DBI::dbGetQuery(con, \"SELECT * FROM bcf_read('variants.vcf.gz') LIMIT 10\") DBI::dbDisconnect(con) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contig_lengths.html","id":null,"dir":"Reference","previous_headings":"","what":"Get contig lengths from VCF/BCF file — vcf_get_contig_lengths","title":"Get contig lengths from VCF/BCF file — vcf_get_contig_lengths","text":"Extracts contig names lengths VCF/BCF header.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contig_lengths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get contig lengths from VCF/BCF file — vcf_get_contig_lengths","text":"","code":"vcf_get_contig_lengths(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contig_lengths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get contig lengths from VCF/BCF file — vcf_get_contig_lengths","text":"filename Path VCF/BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contig_lengths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get contig lengths from VCF/BCF file — vcf_get_contig_lengths","text":"Named integer vector (names = contigs, values = lengths)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contig_lengths.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get contig lengths from VCF/BCF file — vcf_get_contig_lengths","text":"","code":"if (FALSE) { # \\dontrun{ lengths <- vcf_get_contig_lengths(\"variants.vcf.gz\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contigs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get contig names from VCF/BCF file — vcf_get_contigs","title":"Get contig names from VCF/BCF file — vcf_get_contigs","text":"Extracts contig names VCF/BCF header using htslib.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contigs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get contig names from VCF/BCF file — vcf_get_contigs","text":"","code":"vcf_get_contigs(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contigs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get contig names from VCF/BCF file — vcf_get_contigs","text":"filename Path VCF/BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contigs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get contig names from VCF/BCF file — vcf_get_contigs","text":"Character vector contig names","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_contigs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get contig names from VCF/BCF file — vcf_get_contigs","text":"","code":"if (FALSE) { # \\dontrun{ contigs <- vcf_get_contigs(\"variants.vcf.gz\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_sample_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get sample names from a VCF/BCF file — vcf_get_sample_names","title":"Get sample names from a VCF/BCF file — vcf_get_sample_names","text":"Extracts sample names FORMAT column naming pattern.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_sample_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get sample names from a VCF/BCF file — vcf_get_sample_names","text":"","code":"vcf_get_sample_names(file, extension_path = NULL, con = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_sample_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get sample names from a VCF/BCF file — vcf_get_sample_names","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_get_sample_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get sample names from a VCF/BCF file — vcf_get_sample_names","text":"Character vector sample names","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_has_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if VCF/BCF file has an index — vcf_has_index","title":"Check if VCF/BCF file has an index — vcf_has_index","text":"Uses htslib robustly check index presence. Works local files, remote URLs (S3, GCS, HTTP), custom index paths.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_has_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if VCF/BCF file has an index — vcf_has_index","text":"","code":"vcf_has_index(filename, index = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_has_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if VCF/BCF file has an index — vcf_has_index","text":"filename Path VCF/BCF file index Optional explicit index path","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_has_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if VCF/BCF file has an index — vcf_has_index","text":"Logical indicating index exists","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_has_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if VCF/BCF file has an index — vcf_has_index","text":"","code":"if (FALSE) { # \\dontrun{ vcf_has_index(\"variants.vcf.gz\") vcf_has_index(\"s3://bucket/file.vcf.gz\") vcf_has_index(\"file.vcf.gz\", index = \"custom.tbi\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_header_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract VCF header for Parquet key-value storage — vcf_header_metadata","title":"Extract VCF header for Parquet key-value storage — vcf_header_metadata","text":"Extracts full VCF header file embedding Parquet metadata. allows round-tripping back VCF format preserving header information (INFO, FORMAT, FILTER definitions, contigs, samples).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_header_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract VCF header for Parquet key-value storage — vcf_header_metadata","text":"","code":"vcf_header_metadata(file)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_header_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract VCF header for Parquet key-value storage — vcf_header_metadata","text":"file Path VCF, VCF.GZ, BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_header_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract VCF header for Parquet key-value storage — vcf_header_metadata","text":"named list two elements: vcf_header: complete VCF header (lines starting #) RBCFTools_version: Package version created Parquet","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_header_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract VCF header for Parquet key-value storage — vcf_header_metadata","text":"","code":"if (FALSE) { # \\dontrun{ vcf_file <- system.file(\"extdata\", \"1000G_3samples.vcf.gz\", package = \"RBCFTools\") meta <- vcf_header_metadata(vcf_file) cat(meta$vcf_header) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_arrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an Arrow stream from a VCF/BCF file — vcf_open_arrow","title":"Create an Arrow stream from a VCF/BCF file — vcf_open_arrow","text":"Opens VCF BCF file creates Arrow array stream produces record batches. enables efficient, streaming access variant data Arrow format.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_arrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an Arrow stream from a VCF/BCF file — vcf_open_arrow","text":"","code":"vcf_open_arrow(   filename,   batch_size = 10000L,   region = NULL,   samples = NULL,   include_info = TRUE,   include_format = TRUE,   index = NULL,   threads = 0L,   parse_vep = FALSE,   vep_tag = NULL,   vep_columns = NULL,   vep_transcript = c(\"first\", \"all\") )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_arrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an Arrow stream from a VCF/BCF file — vcf_open_arrow","text":"filename Path VCF BCF file batch_size Number records per batch (default: 10000) region Optional region string filtering (e.g., \"chr1:1000-2000\") samples Optional sample filter (comma-separated names \"-\" prefixed exclude) include_info Include INFO fields output (default: TRUE) include_format Include FORMAT/sample data output (default: TRUE) index Optional index file path. NULL (default), uses auto-detection: VCF files try .tbi first, .csi; BCF files use .csi . Useful non-standard index locations presigned URLs different paths. Alternatively, use htslib ##idx## syntax filename (e.g., \"file.vcf.gz##idx##custom.tbi\"). Note: Index required region queries; whole-file streaming needs index. threads Number decompression threads (default: 0 = auto) parse_vep Enable VEP/BCSQ/ANN annotation parsing (default: FALSE). TRUE, annotation fields parsed added typed columns. vep_tag Annotation tag parse (\"CSQ\", \"BCSQ\", \"ANN\") NULL auto-detect. vep_columns Character vector VEP fields extract, NULL fields. vep_transcript transcript extract: \"first\" (default) \"\". \"first\" returns scalar columns (one value per variant). \"\" returns list columns (transcripts per variant).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_arrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an Arrow stream from a VCF/BCF file — vcf_open_arrow","text":"nanoarrow_array_stream object","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_arrow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an Arrow stream from a VCF/BCF file — vcf_open_arrow","text":"","code":"if (FALSE) { # \\dontrun{ # Basic usage stream <- vcf_open_arrow(\"variants.vcf.gz\")  # Read batches while (!is.null(batch <- stream$get_next())) {   # Process batch...   print(nanoarrow::convert_array(batch)) }  # With region filter stream <- vcf_open_arrow(\"variants.vcf.gz\", region = \"chr1:1-1000000\")  # With custom index file (useful for presigned URLs or non-standard locations) stream <- vcf_open_arrow(\"variants.vcf.gz\", index = \"custom_path.tbi\", region = \"chr1\")  # Convert to data frame df <- vcf_to_arrow(\"variants.vcf.gz\", as = \"data.frame\")  # Write to parquet (uses DuckDB, no arrow package needed) vcf_to_parquet_arrow(\"variants.vcf.gz\", \"variants.parquet\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Open a VCF/BCF file as a DuckDB table or view — vcf_open_duckdb","title":"Open a VCF/BCF file as a DuckDB table or view — vcf_open_duckdb","text":"Creates DuckDB connection VCF data loaded table view. Supports -memory file-backed databases, tidy format output, parallel loading chromosome, column selection, optional Hive partitioning.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Open a VCF/BCF file as a DuckDB table or view — vcf_open_duckdb","text":"","code":"vcf_open_duckdb(   file,   extension_path,   table_name = \"variants\",   as_view = TRUE,   dbdir = \":memory:\",   columns = NULL,   region = NULL,   tidy_format = FALSE,   threads = 1L,   partition_by = NULL,   overwrite = FALSE,   config = list() )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Open a VCF/BCF file as a DuckDB table or view — vcf_open_duckdb","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. table_name Name table/view (default: \"variants\") as_view Logical, create VIEW instead materializing TABLE (default: TRUE). Views instant create queries re-read VCF time. Tables slower create subsequent queries fast. dbdir Database directory. Default \":memory:\" -memory database. Use file path persistent storage (e.g., \"variants.duckdb\"). columns Optional character vector columns include. NULL . region Optional genomic region filter (e.g., \"chr1:1000-2000\"). Requires indexed VCF. tidy_format Logical, TRUE loads data tidy (long) format one row per variant-sample combination SAMPLE_ID column. Default FALSE. threads Number threads parallel loading (default: 1). > 1 VCF indexed: views (as_view = TRUE): Creates UNION view per-contig bcf_read() calls. DuckDB parallelizes execution query time. tables (as_view = FALSE): Loads chromosome parallel unions single table. partition_by Optional character vector columns partition creating table (ignored views). Creates partitioned table efficient filtering. supported file-backed databases. overwrite Logical, drop existing table/view exists (default: FALSE). config Named list DuckDB configuration options.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Open a VCF/BCF file as a DuckDB table or view — vcf_open_duckdb","text":"list : con DuckDB connection extension loaded table Name created table/view is_view Logical indicating view created file Path source VCF file dbdir Database directory tidy_format Whether tidy format used row_count Number rows (NULL views)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Open a VCF/BCF file as a DuckDB table or view — vcf_open_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir())  # Open as lazy view (default - instant creation, re-reads VCF each query) vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path) DBI::dbGetQuery(vcf$con, \"SELECT * FROM variants WHERE CHROM = '22'\") vcf_close_duckdb(vcf)  # Parallel view (UNION ALL of per-contig reads, parallelized at query time) vcf <- vcf_open_duckdb(\"wgs.vcf.gz\", ext_path, threads = 8)  # Open as materialized table (slower to create, fast repeated queries) vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path, as_view = FALSE) DBI::dbGetQuery(vcf$con, \"SELECT COUNT(*) FROM variants\")  # Tidy format with specific columns vcf <- vcf_open_duckdb(\"cohort.vcf.gz\", ext_path,   tidy_format = TRUE,   columns = c(\"CHROM\", \"POS\", \"REF\", \"ALT\", \"SAMPLE_ID\", \"FORMAT_GT\") )  # Parallel table loading for large files vcf <- vcf_open_duckdb(\"wgs.vcf.gz\", ext_path, as_view = FALSE, threads = 8)  # Persistent file-backed database vcf <- vcf_open_duckdb(\"variants.vcf.gz\", ext_path,   dbdir = \"my_variants.duckdb\" )  # Partitioned table for efficient sample queries vcf <- vcf_open_duckdb(\"cohort.vcf.gz\", ext_path,   dbdir = \"cohort.duckdb\",   tidy_format = TRUE,   partition_by = \"SAMPLE_ID\" ) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Parallel loading helper for vcf_open_duckdb — vcf_open_duckdb_parallel","title":"Internal: Parallel loading helper for vcf_open_duckdb — vcf_open_duckdb_parallel","text":"Loads VCF data chromosome parallel unions single table.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Parallel loading helper for vcf_open_duckdb — vcf_open_duckdb_parallel","text":"","code":"vcf_open_duckdb_parallel(   con,   file,   table_name,   columns,   tidy_format,   threads,   partition_by )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Parallel loading helper for vcf_open_duckdb — vcf_open_duckdb_parallel","text":"con DuckDB connection file VCF file path table_name Target table name columns Columns select tidy_format Whether use tidy format threads Number threads partition_by Partition columns (unused currently)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Parallel loading helper for vcf_open_duckdb — vcf_open_duckdb_parallel","text":"Row count","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal: Create parallel VIEW using UNION ALL of per-contig bcf_read calls — vcf_open_duckdb_parallel_view","title":"Internal: Create parallel VIEW using UNION ALL of per-contig bcf_read calls — vcf_open_duckdb_parallel_view","text":"Creates VIEW unions bcf_read() calls contig. DuckDB can parallelize execution query time.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal: Create parallel VIEW using UNION ALL of per-contig bcf_read calls — vcf_open_duckdb_parallel_view","text":"","code":"vcf_open_duckdb_parallel_view(   con,   file,   table_name,   columns,   tidy_format,   threads )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal: Create parallel VIEW using UNION ALL of per-contig bcf_read calls — vcf_open_duckdb_parallel_view","text":"con DuckDB connection file VCF file path table_name Target view name columns Columns select tidy_format Whether use tidy format threads Number threads (used limit contigs)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_open_duckdb_parallel_view.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal: Create parallel VIEW using UNION ALL of per-contig bcf_read calls — vcf_open_duckdb_parallel_view","text":"NULL (views row counts)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_arrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Query VCF/BCF with DuckDB — vcf_query_arrow","title":"Query VCF/BCF with DuckDB — vcf_query_arrow","text":"Enables SQL queries VCF files using DuckDB. allows powerful filtering, aggregation, joining operations.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_arrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query VCF/BCF with DuckDB — vcf_query_arrow","text":"","code":"vcf_query_arrow(vcf_files, query, ...)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_arrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query VCF/BCF with DuckDB — vcf_query_arrow","text":"vcf_files Character vector VCF file paths query SQL query string. Use \"vcf\" table name. ... Additional arguments passed vcf_open_arrow","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_arrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query VCF/BCF with DuckDB — vcf_query_arrow","text":"Query result data frame","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_arrow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query VCF/BCF with DuckDB — vcf_query_arrow","text":"","code":"if (FALSE) { # \\dontrun{ # Count variants per chromosome vcf_query_arrow(   \"variants.vcf.gz\",   \"SELECT CHROM, COUNT(*) as n FROM vcf GROUP BY CHROM\" )  # Filter high-quality variants vcf_query_arrow(   \"variants.vcf.gz\",   \"SELECT * FROM vcf WHERE QUAL > 30\" )  # Join multiple VCF files vcf_query_arrow(   c(\"sample1.vcf.gz\", \"sample2.vcf.gz\"),   \"SELECT * FROM vcf WHERE POS BETWEEN 1000 AND 2000\" ) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Query a VCF/BCF file using DuckDB SQL — vcf_query_duckdb","title":"Query a VCF/BCF file using DuckDB SQL — vcf_query_duckdb","text":"Execute SQL query VCF/BCF file using bcf_reader extension. file exposed table via bcf_read() function.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query a VCF/BCF file using DuckDB SQL — vcf_query_duckdb","text":"","code":"vcf_query_duckdb(   file,   extension_path = NULL,   query = NULL,   region = NULL,   tidy_format = FALSE,   con = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query a VCF/BCF file using DuckDB SQL — vcf_query_duckdb","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. query SQL query string. Use bcf_read('{file}') reference file, NULL, returns rows SELECT * bcf_read('{file}'). region Optional genomic region indexed files (e.g., \"chr1:1000-2000\") tidy_format Logical, TRUE returns data tidy (long) format one row per variant-sample combination SAMPLE_ID column. Default FALSE. con Optional existing DuckDB connection (extension already loaded). provided, extension_path ignored.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query a VCF/BCF file using DuckDB SQL — vcf_query_duckdb","text":"data.frame query results","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_query_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query a VCF/BCF file using DuckDB SQL — vcf_query_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ # First build the extension ext_path <- bcf_reader_build(tempdir())  # Basic query - get all variants vcf_query_duckdb(\"variants.vcf.gz\", ext_path)  # Count variants vcf_query_duckdb(\"variants.vcf.gz\", ext_path,   query = \"SELECT COUNT(*) FROM bcf_read('{file}')\" )  # Filter by chromosome vcf_query_duckdb(\"variants.vcf.gz\", ext_path,   query = \"SELECT CHROM, POS, REF, ALT FROM bcf_read('{file}') WHERE CHROM = '22'\" )  # Region query (requires index) vcf_query_duckdb(\"variants.vcf.gz\", ext_path, region = \"chr1:1000000-2000000\")  # Tidy format - one row per variant-sample vcf_query_duckdb(\"cohort.vcf.gz\", ext_path, tidy_format = TRUE)  # Reuse connection for multiple queries con <- vcf_duckdb_connect(ext_path) vcf_query_duckdb(\"file1.vcf.gz\", con = con) vcf_query_duckdb(\"file2.vcf.gz\", con = con) DBI::dbDisconnect(con, shutdown = TRUE) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_read_vep.html","id":null,"dir":"Reference","previous_headings":"","what":"Read VCF with parsed VEP annotations — vcf_read_vep","title":"Read VCF with parsed VEP annotations — vcf_read_vep","text":"Opens VCF file parses VEP/BCSQ/ANN annotations structured columns. convenience wrapper around vcf_open_arrow VEP parsing enabled.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_read_vep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read VCF with parsed VEP annotations — vcf_read_vep","text":"","code":"vcf_read_vep(filename, vep_tag = NULL, vep_columns = NULL, ...)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_read_vep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read VCF with parsed VEP annotations — vcf_read_vep","text":"filename Path VCF/BCF file vep_tag Annotation tag parse (\"CSQ\", \"BCSQ\", \"ANN\") NULL auto-detection vep_columns Character vector VEP fields extract, NULL fields ... Additional arguments passed vcf_to_arrow","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_read_vep.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read VCF with parsed VEP annotations — vcf_read_vep","text":"Data frame VCF columns plus parsed VEP fields separate columns prefixed tag name (e.g., \"CSQ_Consequence\", \"CSQ_SYMBOL\", etc.)","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_read_vep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read VCF with parsed VEP annotations — vcf_read_vep","text":"","code":"if (FALSE) { # \\dontrun{ df <- vcf_read_vep(\"annotated.vcf.gz\",   vep_columns = c(\"Consequence\", \"SYMBOL\", \"AF\", \"gnomAD_AF\") )  # Filter by gnomAD frequency rare <- df[!is.na(df$CSQ_gnomAD_AF) & df$CSQ_gnomAD_AF < 0.001, ] } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_samples_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"List samples in a VCF/BCF file using DuckDB — vcf_samples_duckdb","title":"List samples in a VCF/BCF file using DuckDB — vcf_samples_duckdb","text":"Extract sample names FORMAT column names.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_samples_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List samples in a VCF/BCF file using DuckDB — vcf_samples_duckdb","text":"","code":"vcf_samples_duckdb(file, extension_path = NULL, con = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_samples_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List samples in a VCF/BCF file using DuckDB — vcf_samples_duckdb","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_samples_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List samples in a VCF/BCF file using DuckDB — vcf_samples_duckdb","text":"Character vector sample names","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_samples_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List samples in a VCF/BCF file using DuckDB — vcf_samples_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir()) vcf_samples_duckdb(\"variants.vcf.gz\", ext_path) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_schema_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Get VCF/BCF schema using DuckDB — vcf_schema_duckdb","title":"Get VCF/BCF schema using DuckDB — vcf_schema_duckdb","text":"Returns column names types VCF/BCF file seen DuckDB.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_schema_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get VCF/BCF schema using DuckDB — vcf_schema_duckdb","text":"","code":"vcf_schema_duckdb(file, extension_path = NULL, tidy_format = FALSE, con = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_schema_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get VCF/BCF schema using DuckDB — vcf_schema_duckdb","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. tidy_format Logical, TRUE returns schema tidy format. Default FALSE. con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_schema_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get VCF/BCF schema using DuckDB — vcf_schema_duckdb","text":"data.frame column_name column_type","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_schema_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get VCF/BCF schema using DuckDB — vcf_schema_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir()) vcf_schema_duckdb(\"variants.vcf.gz\", ext_path)  # Compare wide vs tidy schemas vcf_schema_duckdb(\"cohort.vcf.gz\", ext_path) # FORMAT_GT_Sample1, FORMAT_GT_Sample2... vcf_schema_duckdb(\"cohort.vcf.gz\", ext_path, tidy_format = TRUE) # SAMPLE_ID, FORMAT_GT } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_summary_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary statistics for a VCF/BCF file using DuckDB — vcf_summary_duckdb","title":"Summary statistics for a VCF/BCF file using DuckDB — vcf_summary_duckdb","text":"Get summary statistics including variant counts per chromosome.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_summary_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary statistics for a VCF/BCF file using DuckDB — vcf_summary_duckdb","text":"","code":"vcf_summary_duckdb(file, extension_path = NULL, con = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_summary_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary statistics for a VCF/BCF file using DuckDB — vcf_summary_duckdb","text":"file Path VCF, VCF.GZ, BCF file extension_path Path bcf_reader.duckdb_extension file. con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_summary_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary statistics for a VCF/BCF file using DuckDB — vcf_summary_duckdb","text":"list total_variants, n_samples, variants_per_chrom","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_summary_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary statistics for a VCF/BCF file using DuckDB — vcf_summary_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir()) vcf_summary_duckdb(\"variants.vcf.gz\", ext_path) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Read VCF/BCF file into a data frame or list of batches — vcf_to_arrow","title":"Read VCF/BCF file into a data frame or list of batches — vcf_to_arrow","text":"Convenience function read entire VCF file memory R data structure.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read VCF/BCF file into a data frame or list of batches — vcf_to_arrow","text":"","code":"vcf_to_arrow(filename, as = c(\"tibble\", \"data.frame\", \"batches\"), ...)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read VCF/BCF file into a data frame or list of batches — vcf_to_arrow","text":"filename Path VCF BCF file Character string specifying output format: \"tibble\", \"data.frame\", \"batches\" (list nanoarrow arrays) ... Additional arguments passed vcf_open_arrow","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read VCF/BCF file into a data frame or list of batches — vcf_to_arrow","text":"Depends parameter: \"tibble\": tibble \"data.frame\": data.frame \"batches\": list nanoarrow_array objects","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow_ipc.html","id":null,"dir":"Reference","previous_headings":"","what":"Write VCF/BCF to Arrow IPC format — vcf_to_arrow_ipc","title":"Write VCF/BCF to Arrow IPC format — vcf_to_arrow_ipc","text":"Converts VCF/BCF file Arrow IPC stream format efficient storage interoperability Arrow-compatible tools. Uses nanoarrow's native IPC writer streaming output.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow_ipc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write VCF/BCF to Arrow IPC format — vcf_to_arrow_ipc","text":"","code":"vcf_to_arrow_ipc(input_vcf, output_ipc, ...)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow_ipc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write VCF/BCF to Arrow IPC format — vcf_to_arrow_ipc","text":"input_vcf Path input VCF BCF file output_ipc Path output Arrow IPC file (typically .arrows extension) ... Additional arguments passed vcf_open_arrow","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow_ipc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write VCF/BCF to Arrow IPC format — vcf_to_arrow_ipc","text":"Invisibly returns output path","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_arrow_ipc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write VCF/BCF to Arrow IPC format — vcf_to_arrow_ipc","text":"","code":"if (FALSE) { # \\dontrun{ vcf_to_arrow_ipc(\"variants.vcf.gz\", \"variants.arrows\")  # Read back with nanoarrow stream <- nanoarrow::read_nanoarrow(\"variants.arrows\") df <- as.data.frame(stream)  # Or query with DuckDB library(duckdb) con <- dbConnect(duckdb()) dbGetQuery(con, \"SELECT * FROM 'variants.arrows' LIMIT 10\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_arrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","title":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","text":"Converts VCF/BCF file Apache Parquet format efficient storage querying tools like DuckDB, Spark, Python pandas/polars.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_arrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","text":"","code":"vcf_to_parquet_arrow(   input_vcf,   output_parquet,   compression = \"zstd\",   row_group_size = 100000L,   streaming = FALSE,   threads = 1L,   index = NULL,   ... )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_arrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","text":"input_vcf Path input VCF BCF file output_parquet Path output Parquet file compression Compression codec: \"snappy\", \"gzip\", \"zstd\", \"lz4\", \"uncompressed\" row_group_size Number rows per row group (default: 100000) streaming Use streaming mode large files. TRUE, writes temporary Arrow IPC file first (via nanoarrow), converts Parquet via DuckDB. avoids loading entire VCF R memory. Requires DuckDB nanoarrow community extension. Default FALSE. threads Number parallel threads processing (default: 1). threads > 1 file indexed, uses parallel processing splitting work across chromosomes/contigs. thread processes different regions simultaneously. Requires indexed file. See vcf_to_parquet_parallel_arrow details. index Optional explicit index file path ... Additional arguments passed vcf_open_arrow","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_arrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","text":"Invisibly returns output path","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_arrow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","text":"Processing Modes: Standard mode (streaming = FALSE, threads = 1): Loads entire VCF memory data.frame writing. Fast small-medium files. Streaming mode (streaming = TRUE, threads = 1): Two-stage streaming via temporary Arrow IPC file. Minimal memory usage large files. Parallel mode (threads > 1): Requires indexed file. Splits work chromosomes, processing multiple regions simultaneously. Near-linear speedup thread count. Best whole-genome VCFs.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_arrow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write VCF/BCF to Parquet format — vcf_to_parquet_arrow","text":"","code":"if (FALSE) { # \\dontrun{ # Standard mode (fast, loads into memory) vcf_to_parquet_arrow(\"variants.vcf.gz\", \"variants.parquet\")  # Streaming mode for large files (low memory) vcf_to_parquet_arrow(\"huge.vcf.gz\", \"huge.parquet\", streaming = TRUE)  # Parallel mode for whole-genome VCF (requires index) vcf_to_parquet_arrow(\"wgs.vcf.gz\", \"wgs.parquet\", threads = 8)  # Parallel + streaming for massive files vcf_to_parquet_arrow(\"wgs.vcf.gz\", \"wgs.parquet\", threads = 16, streaming = TRUE)  # With zstd compression vcf_to_parquet_arrow(\"variants.vcf.gz\", \"variants.parquet\", compression = \"zstd\")  # Query with DuckDB library(duckdb) con <- dbConnect(duckdb()) dbGetQuery(con, \"SELECT CHROM, POS, REF FROM 'variants.parquet' WHERE CHROM = 'chr1'\") } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Export VCF/BCF to Parquet using DuckDB — vcf_to_parquet_duckdb","title":"Export VCF/BCF to Parquet using DuckDB — vcf_to_parquet_duckdb","text":"Convert VCF/BCF file Parquet format fast subsequent queries.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export VCF/BCF to Parquet using DuckDB — vcf_to_parquet_duckdb","text":"","code":"vcf_to_parquet_duckdb(   input_file,   output_file,   extension_path = NULL,   columns = NULL,   region = NULL,   compression = \"zstd\",   row_group_size = 100000L,   threads = 1L,   tidy_format = FALSE,   partition_by = NULL,   include_metadata = TRUE,   con = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export VCF/BCF to Parquet using DuckDB — vcf_to_parquet_duckdb","text":"input_file Path input VCF, VCF.GZ, BCF file output_file Path output Parquet file directory (using partition_by) extension_path Path bcf_reader.duckdb_extension file. columns Optional character vector columns include. NULL . region Optional genomic region export (requires index) compression Parquet compression: \"snappy\", \"zstd\", \"gzip\", \"none\" row_group_size Number rows per row group (default: 100000) threads Number parallel threads processing (default: 1). threads > 1 file indexed, uses parallel processing splitting work across chromosomes/contigs. See vcf_to_parquet_duckdb_parallel. tidy_format Logical, TRUE exports data tidy (long) format one row per variant-sample combination SAMPLE_ID column. Default FALSE. partition_by Optional character vector columns partition (Hive-style). Creates directory structure like output_dir/SAMPLE_ID=HG00098/data_0.parquet. Particularly useful tidy_format = TRUE partition SAMPLE_ID efficient per-sample queries. DuckDB auto-generates Bloom filters VARCHAR columns like SAMPLE_ID, enabling fast row group pruning. include_metadata Logical, TRUE embeds full VCF header Parquet key-value metadata. Default TRUE. preserves VCF schema information (INFO, FORMAT, FILTER definitions, contigs, samples) enabling round-trip back VCF format. Use parquet_kv_metadata read header back. Note: supported partition_by (Parquet limitation partitioned writes). con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export VCF/BCF to Parquet using DuckDB — vcf_to_parquet_duckdb","text":"Invisible path output file/directory","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export VCF/BCF to Parquet using DuckDB — vcf_to_parquet_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir())  # Export entire file with metadata vcf_to_parquet_duckdb(\"variants.vcf.gz\", \"variants.parquet\", ext_path)  # Read back the embedded metadata parquet_kv_metadata(\"variants.parquet\")  # Export specific columns vcf_to_parquet_duckdb(\"variants.vcf.gz\", \"variants_slim.parquet\", ext_path,   columns = c(\"CHROM\", \"POS\", \"REF\", \"ALT\", \"INFO_AF\") )  # Export a region vcf_to_parquet_duckdb(\"variants.vcf.gz\", \"chr22.parquet\", ext_path,   region = \"chr22\" )  # Export in tidy format (one row per variant-sample) vcf_to_parquet_duckdb(\"cohort.vcf.gz\", \"cohort_tidy.parquet\", ext_path,   tidy_format = TRUE )  # Tidy format with Hive partitioning by SAMPLE_ID (efficient per-sample queries) vcf_to_parquet_duckdb(\"cohort.vcf.gz\", \"cohort_partitioned/\", ext_path,   tidy_format = TRUE,   partition_by = \"SAMPLE_ID\" )  # Partition by both CHROM and SAMPLE_ID for large cohorts vcf_to_parquet_duckdb(\"wgs_cohort.vcf.gz\", \"wgs_partitioned/\", ext_path,   tidy_format = TRUE,   partition_by = c(\"CHROM\", \"SAMPLE_ID\") )  # Parallel mode for whole-genome VCF (requires index) vcf_to_parquet_duckdb(\"wgs.vcf.gz\", \"wgs.parquet\", ext_path, threads = 8) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","title":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","text":"Processes VCF/BCF file parallel splitting work across chromosomes/contigs using DuckDB bcf_reader extension. Requires indexed file. thread processes different chromosome, results merged single Parquet file.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","text":"","code":"vcf_to_parquet_duckdb_parallel(   input_file,   output_file,   extension_path = NULL,   threads = parallel::detectCores(),   compression = \"zstd\",   row_group_size = 100000L,   columns = NULL,   tidy_format = FALSE,   partition_by = NULL,   con = NULL )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","text":"input_file Path input VCF/BCF file (must indexed) output_file Path output Parquet file extension_path Path bcf_reader.duckdb_extension file. threads Number parallel threads (default: auto-detect) compression Parquet compression codec row_group_size Row group size columns Optional character vector columns include tidy_format Logical, TRUE exports data tidy (long) format. Default FALSE. partition_by Optional character vector columns partition (Hive-style). Creates directory structure like output_dir/SAMPLE_ID=HG00098/data_0.parquet. Note: using partition_by, contig's data partitioned separately merged final partitioned output. con Optional existing DuckDB connection (extension loaded).","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","text":"Invisibly returns output path","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb_parallel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","text":"function: Checks index (required parallel processing) Extracts contig names header Processes contig parallel using multiple R processes Writes contig temporary Parquet file Merges temporary files final output using DuckDB Contigs return variants skipped automatically. partition_by specified, function creates Hive-partitioned directory structure. especially useful tidy_format = TRUE partition_by = \"SAMPLE_ID\" efficient per-sample queries large cohorts. DuckDB auto-generates Bloom filters VARCHAR columns like SAMPLE_ID.","code":""},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_duckdb_parallel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel VCF to Parquet conversion using DuckDB — vcf_to_parquet_duckdb_parallel","text":"","code":"if (FALSE) { # \\dontrun{ ext_path <- bcf_reader_build(tempdir())  # Use 8 threads vcf_to_parquet_duckdb_parallel(\"wgs.vcf.gz\", \"wgs.parquet\", ext_path, threads = 8)  # With specific columns vcf_to_parquet_duckdb_parallel(   \"wgs.vcf.gz\", \"wgs.parquet\", ext_path,   threads = 16,   columns = c(\"CHROM\", \"POS\", \"REF\", \"ALT\") )  # Tidy format output vcf_to_parquet_duckdb_parallel(\"wgs.vcf.gz\", \"wgs_tidy.parquet\", ext_path,   threads = 8, tidy_format = TRUE )  # Tidy format with Hive partitioning by SAMPLE_ID vcf_to_parquet_duckdb_parallel(\"wgs_cohort.vcf.gz\", \"wgs_partitioned/\", ext_path,   threads = 8, tidy_format = TRUE, partition_by = \"SAMPLE_ID\" ) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_parallel_arrow.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","title":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","text":"Processes VCF/BCF file parallel splitting work across chromosomes/contigs. Requires indexed file. thread processes different chromosome, results merged single Parquet file.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_parallel_arrow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","text":"","code":"vcf_to_parquet_parallel_arrow(   input_vcf,   output_parquet,   threads = parallel::detectCores(),   compression = \"zstd\",   row_group_size = 100000L,   streaming = FALSE,   index = NULL,   ... )"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_parallel_arrow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","text":"input_vcf Path input VCF/BCF file (must indexed) output_parquet Path output Parquet file threads Number parallel threads (default: auto-detect) compression Compression codec row_group_size Row group size streaming Use streaming mode index Optional explicit index path ... Additional arguments passed vcf_open_arrow","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_parallel_arrow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","text":"Invisibly returns output path","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_parallel_arrow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","text":"function: Checks index (required parallel processing) Extracts contig names header Processes contig parallel using multiple R processes Writes contig temporary Parquet file Merges temporary files final output using DuckDB Contigs return variants skipped automatically.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vcf_to_parquet_parallel_arrow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel VCF to Parquet conversion — vcf_to_parquet_parallel_arrow","text":"","code":"if (FALSE) { # \\dontrun{ # Use 8 threads vcf_to_parquet_parallel_arrow(\"wgs.vcf.gz\", \"wgs.parquet\", threads = 8)  # With streaming mode for large files vcf_to_parquet_parallel_arrow(     \"huge.vcf.gz\", \"huge.parquet\",     threads = 16, streaming = TRUE ) } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_detect_tag.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect VEP annotation tag in VCF file — vep_detect_tag","title":"Detect VEP annotation tag in VCF file — vep_detect_tag","text":"Checks presence CSQ, BCSQ, ANN annotation tags VCF header returns first one found.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_detect_tag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect VEP annotation tag in VCF file — vep_detect_tag","text":"","code":"vep_detect_tag(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_detect_tag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect VEP annotation tag in VCF file — vep_detect_tag","text":"filename Path VCF/BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_detect_tag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect VEP annotation tag in VCF file — vep_detect_tag","text":"Character string tag name (\"CSQ\", \"BCSQ\", \"ANN\"), NA annotation found","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_detect_tag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect VEP annotation tag in VCF file — vep_detect_tag","text":"","code":"if (FALSE) { # \\dontrun{ vep_detect_tag(\"annotated.vcf.gz\")  # Returns \"CSQ\" } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_get_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Get VEP annotation schema from VCF header — vep_get_schema","title":"Get VEP annotation schema from VCF header — vep_get_schema","text":"Parses VEP/BCSQ/ANN header extract field names inferred types. Types inferred using bcftools split-vep conventions.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_get_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get VEP annotation schema from VCF header — vep_get_schema","text":"","code":"vep_get_schema(filename, tag = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_get_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get VEP annotation schema from VCF header — vep_get_schema","text":"filename Path VCF/BCF file tag Optional annotation tag (\"CSQ\", \"BCSQ\", \"ANN\"). NULL (default), auto-detects.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_get_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get VEP annotation schema from VCF header — vep_get_schema","text":"Data frame columns: name Field name (e.g., \"Consequence\", \"SYMBOL\", \"AF\") type Inferred type (\"Integer\", \"Float\", \"String\") index Position pipe-delimited string (0-based) is_list Whether field can multiple values tag name stored attribute.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_get_schema.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get VEP annotation schema from VCF header — vep_get_schema","text":"","code":"if (FALSE) { # \\dontrun{ schema <- vep_get_schema(\"vep_annotated.vcf.gz\") print(schema) #       name    type index is_list # 1   Allele  String     0   FALSE # 2   Consequence String  1    TRUE # 3   IMPACT  String     2   FALSE # ... attr(schema, \"tag\")  # \"CSQ\" } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_has_annotation.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if VCF has VEP-style annotations — vep_has_annotation","title":"Check if VCF has VEP-style annotations — vep_has_annotation","text":"Check VCF VEP-style annotations","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_has_annotation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if VCF has VEP-style annotations — vep_has_annotation","text":"","code":"vep_has_annotation(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_has_annotation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if VCF has VEP-style annotations — vep_has_annotation","text":"filename Path VCF/BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_has_annotation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if VCF has VEP-style annotations — vep_has_annotation","text":"Logical indicating presence CSQ, BCSQ, ANN","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_has_annotation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check if VCF has VEP-style annotations — vep_has_annotation","text":"","code":"if (FALSE) { # \\dontrun{ if (vep_has_annotation(\"file.vcf.gz\")) {   schema <- vep_get_schema(\"file.vcf.gz\") } } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_infer_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Infer type from VEP field name — vep_infer_type","title":"Infer type from VEP field name — vep_infer_type","text":"Uses bcftools split-vep conventions infer type VEP field name.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_infer_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Infer type from VEP field name — vep_infer_type","text":"","code":"vep_infer_type(field_name)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_infer_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Infer type from VEP field name — vep_infer_type","text":"field_name Character vector field names","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_infer_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Infer type from VEP field name — vep_infer_type","text":"Character vector inferred types (\"Integer\", \"Float\", \"String\")","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_infer_type.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Infer type from VEP field name — vep_infer_type","text":"Known integer fields: DISTANCE, STRAND, TSL, GENE_PHENO, HGVS_OFFSET, MOTIF_POS, existing_ORFs, SpliceAI_pred_DP_ Known float fields: AF, AF (e.g., gnomAD_AF), MAX_AF, MOTIF_SCORE_CHANGE, SpliceAI_pred_DS_* others default String.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_infer_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Infer type from VEP field name — vep_infer_type","text":"","code":"vep_infer_type(c(\"SYMBOL\", \"AF\", \"gnomAD_AF\", \"DISTANCE\", \"SpliceAI_pred_DS_AG\")) #> [1] \"String\"  \"Float\"   \"Float\"   \"Integer\" \"Float\"   # [1] \"String\" \"Float\" \"Float\" \"Integer\" \"Float\""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_list_fields.html","id":null,"dir":"Reference","previous_headings":"","what":"List VEP annotation fields in a VCF file — vep_list_fields","title":"List VEP annotation fields in a VCF file — vep_list_fields","text":"Convenience function display available VEP fields types.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_list_fields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List VEP annotation fields in a VCF file — vep_list_fields","text":"","code":"vep_list_fields(filename)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_list_fields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List VEP annotation fields in a VCF file — vep_list_fields","text":"filename Path VCF/BCF file","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_list_fields.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List VEP annotation fields in a VCF file — vep_list_fields","text":"Invisibly returns schema data frame","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_list_fields.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List VEP annotation fields in a VCF file — vep_list_fields","text":"","code":"if (FALSE) { # \\dontrun{ vep_list_fields(\"annotated.vcf.gz\") # VEP Annotation Tag: CSQ # Fields (78 total): #   1. Allele (String) #   2. Consequence (String, list) #   3. IMPACT (String) #   ... } # }"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_parse_record.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse VEP annotation string — vep_parse_record","title":"Parse VEP annotation string — vep_parse_record","text":"Parses CSQ/BCSQ/ANN annotation string structured list data frames, one per transcript/consequence.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_parse_record.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse VEP annotation string — vep_parse_record","text":"","code":"vep_parse_record(csq_value, filename, schema = NULL)"},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_parse_record.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse VEP annotation string — vep_parse_record","text":"csq_value Raw annotation string (pipe-delimited, comma-separated multiple transcripts) filename Path VCF file (schema extraction) schema Optional pre-parsed schema vep_get_schema(). NULL, extracted filename.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_parse_record.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parse VEP annotation string — vep_parse_record","text":"List data frames, one per transcript. data frame one row columns corresponding annotation fields, properly typed.","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/reference/vep_parse_record.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parse VEP annotation string — vep_parse_record","text":"","code":"if (FALSE) { # \\dontrun{ # Get a CSQ value from a VCF csq <- \"A|missense_variant|MODERATE|BRCA1|...\" result <- vep_parse_record(csq, \"annotated.vcf.gz\") result[[1]]$Consequence  # \"missense_variant\" result[[1]]$AF           # 0.001 (numeric) } # }"},{"path":[]},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"parquet-to-vcf-conversion-bcf_writer-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"Parquet to VCF conversion (bcf_writer)","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"Uses VCF header stored Parquet metadata proper formatting Supports wide format (one row per variant) tidy format (one row per variant-sample) Tidy format automatically pivoted back wide VCF format Proper handling array columns (ALT, FILTER, multi-value INFO/FORMAT fields) Auto-indexes output bcftools (configurable via index parameter) Output format determined file extension (.vcf, .vcf.gz, .bcf) Leverages bundled bcftools validation compression","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"vcf-header-metadata-in-parquet-files-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"VCF header metadata in Parquet files","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"include_metadata = TRUE (default) stores complete VCF header Parquet file Preserves INFO, FORMAT, FILTER definitions, contigs, sample names Stores tidy_format flag indicating data layout (“true” “false”) Enables round-trip back VCF format retaining full schema information Also stores RBCFTools version provenance tracking Use parquet_kv_metadata(file) read header back Parquet supported partition_by (Parquet limitation partitioned writes) vcf_header_metadata(file) - Extract full VCF header package version parquet_kv_metadata(file) - Read key-value metadata Parquet files","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"vcf_open_duckdb-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"vcf_open_duckdb","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"-memory file-backed database support Lazy default: as_view = TRUE (default) creates instant views re-read VCF query as_view = FALSE materializes data table fast repeated queries tidy_format = TRUE one row per variant-sample SAMPLE_ID column columns parameter selecting specific columns views: Creates UNION per-contig bcf_read() calls (parallelized query time) tables: Loads chromosome parallel unions Falls back single-threaded warning VCF indexed partition_by creating partitioned tables Returns vcf_duckdb object connection, table name, metadata vcf_close_duckdb() proper cleanup Print method shows connection details","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"native-tidy_format-in-bcf_reader-extension-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"Native tidy_format in bcf_reader extension","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"Much faster SQL-level UNNEST approach (intermediate data duplication) Works projection pushdown - reads requested columns Integrates vcf_*duckdb functions via tidy_format = TRUE parameter vcf_query_duckdb(..., tidy_format = TRUE) - query tidy format vcf_count_duckdb(..., tidy_format = TRUE) - count variant-sample rows vcf_schema_duckdb(..., tidy_format = TRUE) - show tidy schema vcf_to_parquet_duckdb(..., tidy_format = TRUE) - export tidy format vcf_to_parquet_duckdb_parallel(..., tidy_format = TRUE) - parallel tidy export ducklake_load_vcf(..., tidy_format = TRUE) - load VCF tidy format DuckLake Removed vcf_to_parquet_tidy() Removed vcf_to_parquet_tidy_parallel() Removed build_tidy_sql() helper","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"hive-style-partitioning-for-parquet-exports-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"Hive-style partitioning for Parquet exports","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"vcf_to_parquet_duckdb(..., partition_by = \"SAMPLE_ID\") - create Hive-partitioned directory vcf_to_parquet_duckdb_parallel(..., partition_by = \"SAMPLE_ID\") - parallel partitioned export ducklake_load_vcf(..., partition_by = \"SAMPLE_ID\") - load partitioned VCF DuckLake Creates directory structure like output_dir/SAMPLE_ID=HG00098/data_0.parquet DuckDB auto-generates Bloom filters VARCHAR columns (SAMPLE_ID) efficient row group pruning Supports multi-column partitioning, e.g. partition_by = c(\"CHROM\", \"SAMPLE_ID\") Ideal large cohort VCFs exported tidy format","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"ducklake-utilities-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"DuckLake utilities","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"allow_evolution parameter ducklake_load_vcf() ducklake_register_parquet() auto-add new columns via ALTER TABLE ducklake_snapshots(): list snapshot history ducklake_current_snapshot(): get current snapshot ID ducklake_set_commit_message(): set author/message transactions ducklake_options(): get DuckLake configuration ducklake_set_option(): set compression, row group size, etc. ducklake_query_snapshot(): time travel queries specific versions ducklake_list_files(): list Parquet files managed DuckLake ducklake_merge(): upsert data using MERGE syntax","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"other-changes-1-23-0-0-2-9000","dir":"Changelog","previous_headings":"","what":"Other changes","title":"RBCFTools 1.23-0.0.2.9000 (development version)","text":"added processx suggests use instead system2 docs tests renamed vcf_query vcf_query_arrow vcf_to_parquet vcf_to_parquet","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"rbcftools-123-002","dir":"Changelog","previous_headings":"","what":"RBCFTools 1.23-0.0.2","title":"RBCFTools 1.23-0.0.2","text":"renamed vcf_query vcf_query_arrow vcf_to_parquet vcf_to_parquet Version pining release production testing","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"rbcftools-123-0019000-development-version","dir":"Changelog","previous_headings":"","what":"RBCFTools 1.23-0.0.1.9000 (development version)","title":"RBCFTools 1.23-0.0.1.9000 (development version)","text":"bug fixes cli argument passing","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"rbcftools-123-001","dir":"Changelog","previous_headings":"","what":"RBCFTools 1.23-0.0.1","title":"RBCFTools 1.23-0.0.1","text":"First Release start proper semantic versioning Package API","code":""},{"path":"https://rgenomicsetl.github.io/RBCFTools/news/index.html","id":"rbcftools-123-0009000-development-version","dir":"Changelog","previous_headings":"","what":"RBCFTools 1.23-0.0.0.9000 (development version)","title":"RBCFTools 1.23-0.0.0.9000 (development version)","text":"DuckLake catalog connection abstraction: Support DuckDB, SQLite, PostgreSQL, MySQL backends ducklake_connect_catalog(): Abstracted connection function multiple catalog backends ducklake_create_catalog_secret(): Create catalog secrets credential management ducklake_list_secrets(): List existing catalog secrets ducklake_drop_secret(): Remove catalog secrets ducklake_update_secret(): Update existing catalog secrets ducklake_parse_connection_string(): Parse DuckLake connection strings DuckDB bcf_reader extension: Native DuckDB table function querying VCF/BCF files directly. bcf_reader_build(): Build extension source using package’s bundled htslib vcf_duckdb_connect(): Create DuckDB connection extension loaded vcf_query_duckdb(): Query VCF/BCF files SQL DuckDB bcf_reader extension now auto-parses VEP-style annotations (INFO/CSQ, INFO/BCSQ, INFO/ANN) typed VEP_* columns transcripts preserved lists (using vendored parser); builds remain self-contained packaged htslib. Arrow VCF stream (nanoarrow) now aligns VEP parsing semantics DuckDB (schema typing improvements; transcript handling active development). Parallel (contig-based) DuckDB extension Parquet converter. Package version reflects bundled htslib/bcftools versions. parquet conversion now support parrallel threading based conversion vcf2parquet.R script inst/ VCF Arrow streaming via nanoarrow (arrow package required): vcf_open_arrow(): Open VCF/BCF Arrow array stream vcf_to_arrow(): Convert data.frame/tibble/batches vcf_to_parquet(): Export Parquet format via DuckDB vcf_to_arrow_ipc(): Export Arrow IPC format (streaming, memory overhead) vcf_query(): SQL queries VCF files via DuckDB Streaming mode large files: vcf_to_parquet(..., streaming = TRUE) streams VCF -> Arrow IPC -> Parquet without loading R memory. Requires DuckDB nanoarrow extension (auto-installed first use). INFO FORMAT field extraction: INFO fields properly parsed Arrow streams nested INFO data.frame column FORMAT fields extracted nested samples data.frame sample names columns Proper GT field decoding (genotype integers strings like “0|0”, “0/1”) List-type FORMAT fields (AD, GL, PL) correctly extracted Arrow list arrays Header sanity checking based VCF spec (matching htslib’s bcf_hdr_check_sanity()) R warnings emitted correcting non-conformant headers bundles htslib/bcftools cli libraries","code":""}]
