% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vcf_duckdb.R
\name{vcf_to_parquet_tidy_parallel}
\alias{vcf_to_parquet_tidy_parallel}
\title{Parallel tidy VCF to Parquet conversion}
\usage{
vcf_to_parquet_tidy_parallel(
  input_file,
  output_file,
  extension_path = NULL,
  threads = parallel::detectCores(),
  compression = "zstd",
  row_group_size = 100000L,
  columns = NULL,
  con = NULL
)
}
\arguments{
\item{input_file}{Path to input VCF, VCF.GZ, or BCF file}

\item{output_file}{Path to output Parquet file}

\item{extension_path}{Path to the bcf_reader.duckdb_extension file.}

\item{threads}{Number of parallel threads (default: auto-detect)}

\item{compression}{Parquet compression: "snappy", "zstd", "gzip", or "none"}

\item{row_group_size}{Number of rows per row group (default: 100000)}

\item{columns}{Optional character vector of non-FORMAT columns to include.
FORMAT columns are always included and transformed to tidy format.
NULL includes all columns.}

\item{con}{Optional existing DuckDB connection (with extension loaded).}
}
\value{
Invisibly returns the output path
}
\description{
Processes VCF/BCF file in parallel by splitting work across chromosomes/contigs,
converting to tidy (long) format. Requires an indexed file.
}
\keyword{internal}
